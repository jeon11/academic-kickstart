<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>python | Jin Jeon</title>
    <link>https://jinjeon.me/tags/python/</link>
      <atom:link href="https://jinjeon.me/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <description>python</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2024 developed by Jin with HTML/CSS/Markdown and ☕️ </copyright><lastBuildDate>Sat, 01 May 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://jinjeon.me/img/icon.png</url>
      <title>python</title>
      <link>https://jinjeon.me/tags/python/</link>
    </image>
    
    <item>
      <title>Sentiment Analysis, Textual Data Analysis, and Visualization Using Natural Language API</title>
      <link>https://jinjeon.me/post/textual-data-analysis/</link>
      <pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate>
      <guid>https://jinjeon.me/post/textual-data-analysis/</guid>
      <description>&lt;!-- raw HTML omitted --&gt;
&lt;h3 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#link1&#34;&gt;What is Google Cloud API?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#link2&#34;&gt;Survey Data in User Research&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#link3&#34;&gt;Natural Language API Features&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;
3.1 &lt;a href=&#34;#link3.1&#34;&gt;Entity Analysis&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;
3.2 &lt;a href=&#34;#link3.2&#34;&gt;Sentiment Analysis&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;
3.3 &lt;a href=&#34;#link3.3&#34;&gt;Entity Sentiment Analysis&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#link4&#34;&gt;Loading in data using Google Sheets API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#link5&#34;&gt;Dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#link6&#34;&gt;Data Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#link7&#34;&gt;Research Question&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;
7.1 &lt;a href=&#34;#link7.1&#34;&gt;A. Health Rating by Gender&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;
7.2 &lt;a href=&#34;#link7.2&#34;&gt;B. Health Rating by Age Group&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;
7.3 &lt;a href=&#34;#link7.3&#34;&gt;C. T-test for Statistical Signifcance&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;
7.4 &lt;a href=&#34;#link7.4&#34;&gt;D. Health Rating by Age &amp;amp; Gender Group&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;
7.5 &lt;a href=&#34;#link7.5&#34;&gt;E. Iteratively Running t-test Within Each Age Group&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#link8&#34;&gt;Data Visualization&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;
8.1 &lt;a href=&#34;#link8.1&#34;&gt;Characterizing Textual Data Through Wordcloud&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#link9&#34;&gt;Conclusion&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h3 id=&#34;a-namelink1-what-is-google-cloud-api-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; What is Google Cloud API? &lt;!-- raw HTML omitted --&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Google Cloud Platform&lt;/strong&gt; is a suite of cloud computing services that lets developers interact with APIs that involve data storage, data analytics, and machine learning. In this notebook, I build on to the previous notebook to call in the spreadsheets from Google Drive, and run textual data analysis using the Cloud Natural Language API and vector space models.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://cloud.google.com/natural-language&#34;&gt;Natural Language AI&lt;/a&gt;&lt;/strong&gt; is an API available in Google Cloud. It uses machine learning to analyze texts through sentiment analysis and extract information about the text itself. It offers three types of models:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Auto ML&lt;/strong&gt;: that allows you to train your own model&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;!-- raw HTML omitted --&gt;Natural Language API&lt;!-- raw HTML omitted --&gt;&lt;/strong&gt;: that offers pre-trained models to quickly boot up NLP.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Healthcare Natural Language AI&lt;/strong&gt;: that is specific for medical texts.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For the sake of time scope and complexity of the project, let&amp;rsquo;s use the Natural Language API to call in a pre-trained model to analyze textual data. The demo of the model can be found online here: &lt;a href=&#34;https://cloud.google.com/natural-language&#34;&gt;https://cloud.google.com/natural-language&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;a-namelink2-survey-data-in-user-research-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; Survey Data in User Research &lt;!-- raw HTML omitted --&gt;&lt;/h3&gt;
&lt;p&gt;As a UX researcher, survey studies are essential for understanding the users because they can be quickly developed and sent out to receive a good amount of sample in a short period of time. &lt;strong&gt;Surveys are powerful tools to be utilized for conducting preliminary research at the discovery stage to explore the general problem space and user behaviors.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;One of the free and efficient tools is the Google Forms. While it can automatically generate pie graphs and bar graphs to summarize the survey results, the results are often too limited. &lt;strong&gt;As researchers, we might be interested in learning more in depth about the data. After all, it is researchers&#39; role to develop a keen sense to analyze the data and drive insights.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For instance, the screenshots below show sample summaries of what Google Form summary is capable of doing.&lt;/p&gt;
&lt;h4 id=&#34;breakdown-of-participants-age-range&#34;&gt;Breakdown of participants&#39; age range&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./age.png&#34; alt=&#34;Age Breakdown&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;participants-self-perception-of-their-health-wellness&#34;&gt;Participants&#39; self perception of their health wellness&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./rating.png&#34; alt=&#34;Rating by Participants&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The graphs above do not show any relationship between the data.&lt;/strong&gt; To drive more meaningful insights, we would want to explore if there are any relationships between the data. For example, we would want to know how self perception of health wellness varies by different age groups. Do older people perceive themselves to be less healthy than young people do? While the ratings are subjective, the analysis itself can hint towards meaningful insights.&lt;/p&gt;
&lt;h4 id=&#34;objectives&#34;&gt;Objectives&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;I use GoogleSheets API to call in the data and analyze the survey results to visualize the relationship between data and test statistical significance. I also incorporate Natural Language API to analyze textual data collected from the survey, and visualize them through violin graphs and word cloud.&lt;/strong&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;a-namelink3-natural-language-api-features-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; Natural Language API Features &lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Before diving straight to working with data, let&amp;rsquo;s take a look at some of the features of NL API.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;setup&#34;&gt;Setup&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Imports the Google Cloud client library&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; google.cloud &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; language_v1

&lt;span style=&#34;color:#75715e&#34;&gt;# set environment for credentials (need to be called with every start of instance)&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# refer the reference tab for setting credentials&lt;/span&gt;
os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;environ[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;GOOGLE_APPLICATION_CREDENTIALS&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/Users/Jin/google-cloud-sdk/natural-language-api.json&amp;#34;&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# Instantiates a client&lt;/span&gt;
client &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; language_v1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LanguageServiceClient()

&lt;span style=&#34;color:#75715e&#34;&gt;# Available types: PLAIN_TEXT, HTML&lt;/span&gt;
type_ &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; language_v1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Document&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Type&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;PLAIN_TEXT

encoding_type &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; language_v1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;EncodingType&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;UTF8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For the scope of this project, let&amp;rsquo;s look at some specific methods that NL API offers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. Entity analysis&lt;/strong&gt;&lt;!-- raw HTML omitted --&gt;
&lt;strong&gt;2. Sentiment analysis&lt;/strong&gt;&lt;!-- raw HTML omitted --&gt;
&lt;strong&gt;3. Entity Sentiment analysis&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;a-namelink31-1-entity-analysis-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; 1. Entity analysis &lt;!-- raw HTML omitted --&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;analyze_entities&lt;/code&gt;: inspects the given text for known entities (proper nouns such as public figures, landmarks, etc.), and returns information about those entities.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# grab a random text from wikipedia&lt;/span&gt;
text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;u&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;The University of Washington is a public research university in Seattle, Washington.&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        Ana Mari Cauce is the president.&amp;#34;&lt;/span&gt;

document &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;: text, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;type_&amp;#34;&lt;/span&gt;: type_}

response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; client&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;analyze_entities(request &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;document&amp;#39;&lt;/span&gt;: document, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;encoding_type&amp;#39;&lt;/span&gt;: encoding_type})

&lt;span style=&#34;color:#75715e&#34;&gt;# Loop through entitites returned from the API&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; entity &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; response&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;entities:
    print(&lt;span style=&#34;color:#e6db74&#34;&gt;u&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Entity name: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(entity&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name))

    &lt;span style=&#34;color:#75715e&#34;&gt;# Get entity type, e.g. PERSON, LOCATION, ADDRESS, NUMBER, et al&lt;/span&gt;
    print(&lt;span style=&#34;color:#e6db74&#34;&gt;u&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Entity type: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(language_v1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Entity&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Type(entity&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;type_)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name))

    &lt;span style=&#34;color:#75715e&#34;&gt;# Get the salience score associated with the entity in the [0, 1.0] range&lt;/span&gt;
    print(&lt;span style=&#34;color:#e6db74&#34;&gt;u&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Salience score: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(entity&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;salience) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Entity name: University of Washington
Entity type: ORGANIZATION
Salience score: 0.7374827265739441

Entity name: Ana Mari Cauce
Entity type: PERSON
Salience score: 0.11040862649679184

Entity name: Washington
Entity type: LOCATION
Salience score: 0.07763731479644775

Entity name: Seattle
Entity type: LOCATION
Salience score: 0.07447130978107452
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;a-namelink32-2-sentiment-analysis-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; 2. Sentiment analysis &lt;!-- raw HTML omitted --&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;analyze_sentiment&lt;/code&gt;: inspects the given text and identifies the prevailing emotional opinion within the text, especially to determine a writer&amp;rsquo;s attitude as positive, negative, or neutral.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;analyze_sentiment&lt;/span&gt;(text):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    a simple function created to run sentiment analysis for a given text.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Parameters
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    ----------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    text : str
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        string of text to be analyzed
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Returns
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    -------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    sentiment.score: float
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        sentiment score between -1.0 (negative sentiment) and 1.0 (positive sentiment).
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    sentiment.magnitude: float
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        a non-negative number in the [0, +inf) range, which represents the absolute &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        magnitude of sentiment regardless of score (positive or negative).
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    document &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; language_v1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Document(content&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;text, type_&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;language_v1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Document&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Type&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;PLAIN_TEXT)

    &lt;span style=&#34;color:#75715e&#34;&gt;# Detects the sentiment of the text&lt;/span&gt;
    sentiment &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; client&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;analyze_sentiment(request&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;document&amp;#39;&lt;/span&gt;: document})&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;document_sentiment

    print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Text: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(text))
    print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Sentiment: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;, &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(sentiment&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;score, sentiment&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;magnitude))

    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; sentiment&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;score, sentiment&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;magnitude
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Let&amp;rsquo;s try feeding in some random sentences and see how sentiments come out.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# The text to analyze&lt;/span&gt;
text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;u&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;The dish was delightfully surprising.&amp;#34;&lt;/span&gt;
text2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;u&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;The overall experience was terrible.&amp;#34;&lt;/span&gt;

analyze_sentiment(text)
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
_, _ &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; analyze_sentiment(text2)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Text: The dish was delightfully surprising.
Sentiment: 0.8999999761581421, 0.8999999761581421


Text: The overall experience was terrible.
Sentiment: -0.800000011920929, 0.800000011920929
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;a-namelink33-3-entity-sentiment-analysis-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; 3. Entity sentiment analysis &lt;!-- raw HTML omitted --&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;analyze_entity_sentiment&lt;/code&gt;: combines both entity analysis and sentiment analysis and attempts to determine the sentiment (positive or negative) expressed about entities within the text.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;analyze_entity_sentiment&lt;/span&gt;(text):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    a simple function to run entity sentiment analysis for a given text.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Parameters
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    ----------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    text : str
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        string of text to be analyzed
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Returns
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    -------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    entity.name: str
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        name of the entity identified
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    entity.type.name: str
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        type of the entity identified
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    sentiment.score: float
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        sentiment score between -1.0 (negative sentiment) and 1.0 (positive sentiment).
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    sentiment.magnitude: float
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        a non-negative number in the [0, +inf) range, which represents the absolute &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        magnitude of sentiment regardless of score (positive or negative).
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    document &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;: text, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;type_&amp;#34;&lt;/span&gt;: type_}

    encoding_type &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; language_v1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;EncodingType&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;UTF8

    response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; client&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;analyze_entity_sentiment(request &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;document&amp;#39;&lt;/span&gt;: document, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;encoding_type&amp;#39;&lt;/span&gt;: encoding_type})
    &lt;span style=&#34;color:#75715e&#34;&gt;# Loop through entitites returned from the API&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; entity &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; response&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;entities:
        print(&lt;span style=&#34;color:#e6db74&#34;&gt;u&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Entity name: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(entity&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name))

        &lt;span style=&#34;color:#75715e&#34;&gt;# Get entity type, e.g. PERSON, LOCATION, ADDRESS, NUMBER, et al&lt;/span&gt;
        print(&lt;span style=&#34;color:#e6db74&#34;&gt;u&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Entity type: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(language_v1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Entity&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Type(entity&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;type_)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name))

        &lt;span style=&#34;color:#75715e&#34;&gt;# Get the salience score associated with the entity in the [0, 1.0] range&lt;/span&gt;
        print(&lt;span style=&#34;color:#e6db74&#34;&gt;u&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Salience score: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(entity&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;salience))

        &lt;span style=&#34;color:#75715e&#34;&gt;# Get the aggregate sentiment expressed for this entity in the provided document.&lt;/span&gt;
        sentiment &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; entity&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sentiment
        print(&lt;span style=&#34;color:#e6db74&#34;&gt;u&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Entity sentiment score: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(sentiment&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;score))
        print(&lt;span style=&#34;color:#e6db74&#34;&gt;u&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Entity sentiment magnitude: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(sentiment&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;magnitude))
        print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; entity&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name, language_v1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Entity&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Type(entity&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;type_)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name, sentiment&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;score, sentiment&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;magnitude
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Let&amp;rsquo;s try feeding in one neutral sentence, and a positive sentence.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;u&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;The University of Washington is a public research university in Seattle, Washington.&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        The HCDE Department offers amazing opportunities to study UX and HCI.&amp;#34;&lt;/span&gt;

_, _, _, _ &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; analyze_entity_sentiment(text)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Entity name: University of Washington
Entity type: ORGANIZATION
Salience score: 0.7403186559677124
Entity sentiment score: 0.0
Entity sentiment magnitude: 0.0


Entity name: Washington
Entity type: LOCATION
Salience score: 0.07140954583883286
Entity sentiment score: 0.0
Entity sentiment magnitude: 0.0


Entity name: Seattle
Entity type: LOCATION
Salience score: 0.06301160156726837
Entity sentiment score: 0.0
Entity sentiment magnitude: 0.0


Entity name: HCDE Department
Entity type: ORGANIZATION
Salience score: 0.04862694814801216
Entity sentiment score: 0.8999999761581421
Entity sentiment magnitude: 0.8999999761581421


Entity name: UX
Entity type: OTHER
Salience score: 0.03587672486901283
Entity sentiment score: 0.699999988079071
Entity sentiment magnitude: 0.699999988079071


Entity name: HCI
Entity type: OTHER
Salience score: 0.025248046964406967
Entity sentiment score: 0.800000011920929
Entity sentiment magnitude: 0.800000011920929


Entity name: opportunities
Entity type: OTHER
Salience score: 0.015508485026657581
Entity sentiment score: 0.8999999761581421
Entity sentiment magnitude: 0.8999999761581421
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the result above, we can see that the first sentiment of the entities identified in the first sentence, such as &amp;lsquo;University of Washington&amp;rsquo; or &amp;lsquo;Seattle&amp;rsquo; has a sentiment score of 0.0 which means neutral. This makes sense because the sentence was directly pulled from Wikipedia. On the other hand, the second sentence I wrote highlights &amp;lsquo;HCDE Department&amp;rsquo; as an entity with positive sentiment score of 0.8999.&lt;/p&gt;
&lt;h4 id=&#34;so-whats-next&#34;&gt;So what&amp;rsquo;s next?&lt;/h4&gt;
&lt;p&gt;We can interchangeably use the two functions defined &lt;code&gt;analyze_sentiment&lt;/code&gt; and &lt;code&gt;analyze_entity_sentiment&lt;/code&gt; to identify the overall sentiment of a given text or entity if specified in the data analysis process.&lt;/p&gt;
&lt;hr&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;a-namelink4-loading-in-data-using-google-sheets-api-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; Loading in data using Google Sheets API &lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;The following code will only run if you have your Google &lt;code&gt;credential.json&lt;/code&gt; and &lt;code&gt;token.json&lt;/code&gt; within the working directory.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; __future__ &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; print_function
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os.path
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; googleapiclient.discovery &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; build
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; google_auth_oauthlib.flow &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; InstalledAppFlow
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; google.auth.transport.requests &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Request
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; google.oauth2.credentials &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Credentials

SCOPES &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://www.googleapis.com/auth/spreadsheets.readonly&amp;#39;&lt;/span&gt;]
SPREADSHEET_ID &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;11Den6g5nuR4B2CCUML1KrA0bEZXRpPZ7t83Ieyi7NJ4&amp;#39;&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# Specify which sheet or row/column of data to call in&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# refer to https://developers.google.com/sheets/api/guides/concepts#a1_notation for detail&lt;/span&gt;
RANGE_NAME &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;health_data&amp;#39;&lt;/span&gt;

creds &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Credentials&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_authorized_user_file(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;token.json&amp;#39;&lt;/span&gt;, SCOPES)
service &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; build(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sheets&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;v4&amp;#39;&lt;/span&gt;, credentials&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;creds)

&lt;span style=&#34;color:#75715e&#34;&gt;# Call the Sheets API to read in the data&lt;/span&gt;
sheet &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; service&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;spreadsheets()
result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sheet&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(spreadsheetId &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SPREADSHEET_ID,
                            range &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RANGE_NAME)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;execute()
values &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; result&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;values&amp;#39;&lt;/span&gt;, [])

&lt;span style=&#34;color:#75715e&#34;&gt;# convert the sheet to pandas dataframe so we can easily manipulate the data&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; pd

data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(values[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:], columns&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;values[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])

&lt;span style=&#34;color:#75715e&#34;&gt;# let&amp;#39;s confirm&lt;/span&gt;
print(type(data))

data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;class &#39;pandas.core.frame.DataFrame&#39;&amp;gt;

(71, 27)
&lt;/code&gt;&lt;/pre&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;hr&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;a-namelink5-dataset-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; Dataset &lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;From the code above, we translated the data into pandas dataframe. Using &lt;code&gt;data.shape&lt;/code&gt;, we know that there are total 27 questions collected from 71 participants. For simplicity, I remove any data that does not prefer to disclose gender. This brings the data size to 68. Due to the extensive length and branching logic within the survey, the data becomes more textual and qualitative for questions or columns in the back. I will primarily use selected columns that are of interest.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s have a quick glance at the dataset.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# for simplicity, let&amp;#39;s constrain the gender option to only two&lt;/span&gt;
gender_options &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Man&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Woman&amp;#39;&lt;/span&gt;]
data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data[data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;What is your gender?&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;isin(gender_options)]

print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;There are total &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(len(data)) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; participants.&amp;#39;&lt;/span&gt;)
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;The survey consists of &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; questions (columns in the dataframe).&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# convert the column string values to integers&lt;/span&gt;
data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;How would you rate your health?&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;How would you rate your health?&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(int)

data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;There are total 69 participants.
The survey consists of 27 questions (columns in the dataframe).
&lt;/code&gt;&lt;/pre&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;hr&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;a-namelink6-data-analysis-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; Data Analysis &lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;Now that we have seen the general dataframe structure, let&amp;rsquo;s explore probing the data for analysis.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; collections &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Counter
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; re
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; sns
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; nltk.corpus &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; stopwords
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; warnings
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; wordcloud &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; WordCloud, STOPWORDS, ImageColorGenerator
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; scipy
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tabulate &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tabulate

warnings&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;simplefilter(action&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ignore&amp;#39;&lt;/span&gt;, category&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;FutureWarning&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# suppress any warning&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_color_codes(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pastel&amp;#39;&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# set color&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;querying-data&#34;&gt;Querying data&lt;/h3&gt;
&lt;p&gt;Before we play around with data, let&amp;rsquo;s query out the data that are of interest. This way we can manipulate the data more effectively without having to call on the entire dataset &lt;code&gt;data&lt;/code&gt; everytime.&lt;/p&gt;
&lt;p&gt;There are total 7 different age groups.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# let&amp;#39;s divde the data by gender first&lt;/span&gt;
females &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;What is your gender?&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Woman&amp;#39;&lt;/span&gt;]
males &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;What is your gender?&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Man&amp;#39;&lt;/span&gt;]

&lt;span style=&#34;color:#75715e&#34;&gt;# let&amp;#39;s also create dataset divided by age group&lt;/span&gt;
age_under18 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;What age range are you?&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Under 18&amp;#39;&lt;/span&gt;]
age_18to24 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;What age range are you?&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;18 - 24&amp;#39;&lt;/span&gt;]
age_25to34 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;What age range are you?&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;25 - 34&amp;#39;&lt;/span&gt;]
age_35to44 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;What age range are you?&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;35 - 44&amp;#39;&lt;/span&gt;]
age_45to54 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;What age range are you?&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;45 - 54&amp;#39;&lt;/span&gt;]
age_55to64 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;What age range are you?&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;55 - 64&amp;#39;&lt;/span&gt;]
age_over65 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;What age range are you?&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;65 or older&amp;#39;&lt;/span&gt;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;print(len(males))
print(len(females))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;31
38
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;a-namelink7-research-question-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; Research Question &lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;em&gt;How does self-perception of health rating differ by gender and age?&lt;/em&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Participants were asked, How would you rate your health? (5 being healthy, 1 being not healthy).&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h3 id=&#34;a-namelink71-a-health-rating-by-gender-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; A. Health rating by gender &lt;!-- raw HTML omitted --&gt;&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s breakdown the data to see how self-perception of health wellness varies by gender and different age groups. In the code below, I first quary females and males from the data.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# columns[4] is the column for health rating&lt;/span&gt;
mean_males &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(males[males&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns[&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;]])
mean_females &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(females[females&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns[&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;]])

print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Mean of males&amp;#39; self-health wellness: &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(mean_males))
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Mean of females&amp;#39; self-health wellness: &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(mean_females))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Mean of males&#39; self-health wellness: 3.5161290322580645
Mean of females&#39; self-health wellness: 3.4473684210526314
&lt;/code&gt;&lt;/pre&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h3 id=&#34;a-namelink72-b-health-rating-by-age-group-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; B. Health rating by age group &lt;!-- raw HTML omitted --&gt;&lt;/h3&gt;
&lt;p&gt;Now let&amp;rsquo;s breakdown the data to see how self-perception of health wellness varies by different age groups.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;age &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;What age range are you?&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;How would you rate your health?&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()
age
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;What age range are you?
18 - 24        3.615385
25 - 34        3.285714
35 - 44        3.500000
45 - 54        3.375000
55 - 64        3.600000
65 or older    4.000000
Under 18       3.000000
Name: How would you rate your health?, dtype: float64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conversely, the age group 65 or older actually has the highest self-perception of wellness.&lt;/strong&gt; The youngest group (age under 18) rated the lowest.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h3 id=&#34;a-namelink73-c-t-test-for-statistical-signifcance-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; C. T-test for statistical signifcance &lt;!-- raw HTML omitted --&gt;&lt;/h3&gt;
&lt;p&gt;With small samples of the two demographic groups &lt;code&gt;65 or older&lt;/code&gt; and &lt;code&gt;Under 18&lt;/code&gt;, we are not sure if the difference we see here is significant. &lt;strong&gt;Let&amp;rsquo;s run a quick t-test to see if the difference we are seeing is statistically significant.&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;t, p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; scipy&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ttest_ind(age_over65[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;How would you rate your health?&amp;#39;&lt;/span&gt;], age_under18[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;How would you rate your health?&amp;#39;&lt;/span&gt;])

print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;t: &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;round(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)))  
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;p: &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;round(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)))  &lt;span style=&#34;color:#75715e&#34;&gt;# the p-val should be less than 0.05 in general to assume the difference we observe is signifcant&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;t: 2.8983
p: 0.0199
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see the p-value is 0.01 which is signifcant, which is one interesting find! So we can say that within this dataset, the people age over 65 perceive themselves to be more healthy than teenagers would do.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h3 id=&#34;a-namelink74-d-health-rating-by-age--gender-group-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; D. Health rating by age &amp;amp; gender group &lt;!-- raw HTML omitted --&gt;&lt;/h3&gt;
&lt;p&gt;Now let&amp;rsquo;s breakdown by both gender and different age groups to look at how the self perception of health wellness change.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;age_gender &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;What age range are you?&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;What is your gender?&amp;#39;&lt;/span&gt;])[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;How would you rate your health?&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;round(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)

age_gender
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;What age range are you?  What is your gender?
18 - 24                  Man                     3.43
                         Woman                   3.83
25 - 34                  Man                     3.43
                         Woman                   3.21
35 - 44                  Man                     3.80
                         Woman                   3.29
45 - 54                  Man                     3.40
                         Woman                   3.33
55 - 64                  Man                     3.33
                         Woman                   4.00
65 or older              Man                     4.00
                         Woman                   4.00
Under 18                 Man                     3.00
                         Woman                   3.00
Name: How would you rate your health?, dtype: float64
&lt;/code&gt;&lt;/pre&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h3 id=&#34;a-namelink75-e-iteratively-running-t-test-within-each-age-group-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; E. Iteratively running t-test within each age group &lt;!-- raw HTML omitted --&gt;&lt;/h3&gt;
&lt;p&gt;We have several different age groups with each male and female gender group. Within each age group, let&amp;rsquo;s run a t-test to see if there are any significant observed differences.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;gender_options &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Man&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Woman&amp;#39;&lt;/span&gt;]
age_groups &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age_under18&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age_18to24&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age_25to34&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age_35to44&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age_45to54&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age_55to64&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age_over65&amp;#39;&lt;/span&gt;]

table &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
table&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age group&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;t value&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;p value&amp;#39;&lt;/span&gt;])

&lt;span style=&#34;color:#75715e&#34;&gt;# iteratively run for t-tests within each age group defined in the list variable &amp;#39;age_groups&amp;#39;&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(age_groups)):
    data_string &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;[&amp;#39;How would you rate your health?&amp;#39;]&amp;#34;&lt;/span&gt;
    eval_string1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; age_groups[i] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.loc[&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; age_groups[i] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;[&amp;#39;What is your gender?&amp;#39;] == &amp;#39;Man&amp;#39;]&amp;#34;&lt;/span&gt;
    a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; eval(eval_string1 &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; data_string)
    eval_string2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; age_groups[i] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.loc[&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; age_groups[i] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;[&amp;#39;What is your gender?&amp;#39;] == &amp;#39;Woman&amp;#39;]&amp;#34;&lt;/span&gt;
    b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; eval(eval_string2 &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; data_string)
&lt;span style=&#34;color:#75715e&#34;&gt;#     strings_combined = &amp;#39;scipy.stats.ttest_ind(a, b)&amp;#39;&lt;/span&gt;

    t, p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; eval(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;scipy.stats.ttest_ind(a, b)&amp;#39;&lt;/span&gt;)

    &lt;span style=&#34;color:#75715e&#34;&gt;# we use a package called tabulate to print out a formatted table&lt;/span&gt;
    table&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append([age_groups[i], t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;round(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;) ,p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;round(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)])

print(tabulate(table, headers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;firstrow&amp;#39;&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;age group      t value    p value
-----------  ---------  ---------
age_under18   nan        nan
age_18to24     -1.1315     0.2819
age_25to34      0.4504     0.6575
age_35to44      0.9682     0.3558
age_45to54      0.1637     0.8754
age_55to64     -0.7746     0.495
age_over65      0          1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;We see that the p-values are all above 0.05 which means that there are no observed significant differences in gender within each age group.&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;a-namelink8-data-visualization-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; Data Visualization &lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s first try plotting a simple visual violin plot.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;age_plot &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;catplot(x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;What age range are you?&amp;#39;&lt;/span&gt;, y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;How would you rate your health?&amp;#39;&lt;/span&gt;, \
                       hue&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;What is your gender?&amp;#39;&lt;/span&gt;, kind&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;violin&amp;#34;&lt;/span&gt;, data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;data);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./TextualDataAnalysis_39_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;a-namelink81-characterizing-textual-data-through-wordcloud-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; Characterizing textual data through wordcloud &lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s change focus and try analyzing textual inputs from the participants. We will analyze the column How is your health and/or fitness information being used? question to identify any emerging keywords using the word cloud representation. Disclaimer: The result here is not such a useful or accurate representation as the stopwords did not clearly filter out.&lt;/p&gt;
&lt;p&gt;We first call in a list of stopwords to filter out any unnecessary words, such as &amp;lsquo;I&amp;rsquo;, &amp;lsquo;and&amp;rsquo;, and etc. We then flatten out all the responses into a single list of words.&lt;/p&gt;
&lt;h3 id=&#34;is-there-gender-difference-in-how-they-use-health-data-text-responses&#34;&gt;Is there gender difference in how they use health data (text responses)?&lt;/h3&gt;
&lt;p&gt;Participants were asked, &amp;ldquo;How is your health and/or fitness information being used?&amp;rdquo; Here, I try to breakdown the text data through representation of wordcloud, and see if there any characteristics found in each gender.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# builtin stopword sets from nltk&lt;/span&gt;
stop &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; set(stopwords&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;words(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;english&amp;#39;&lt;/span&gt;))


&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;plot_wordcloud&lt;/span&gt;(df, col, separator&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Plots a wordcloud of given dataframe and specific column. The text is counted at word level.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Parameters
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    ----------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    df: pandas dataframe
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        dataframe that contains textual data
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    col: int
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        integer that points to the specific column with textual data
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    separator: str (default: None)
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        string specified to breakdown the text by. Default is empty space
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Returns
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    -------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Wordcloud plot
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    list of most common words in the dataframe
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# filter out any NaNs&lt;/span&gt;
    response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [x &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; df[df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns[col]] &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; x]
    &lt;span style=&#34;color:#75715e&#34;&gt;# filter out any None&lt;/span&gt;
    response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [x &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; response &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;]

    word_dict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(response)):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; separator &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
            word_dict&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(response[i]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split())
        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
            word_dict&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(response[i]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(separator))
    word_filtered &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []

    &lt;span style=&#34;color:#75715e&#34;&gt;# flatten the list and lower all letter cases&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; sublist &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; word_dict:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; item &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sublist:
            word_filtered&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(item&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lower())

    &lt;span style=&#34;color:#75715e&#34;&gt;# remove stopwords&lt;/span&gt;
    word_filtered &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [x &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; word_filtered &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; stop]

    word_filtered &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [word&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;,&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#39;&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; word &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; word_filtered]

    &lt;span style=&#34;color:#75715e&#34;&gt;# print most common words&lt;/span&gt;
    most_common_words &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Counter(word_filtered)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;most_common(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)
    print(most_common_words)

    &lt;span style=&#34;color:#75715e&#34;&gt;# plot wordcloud&lt;/span&gt;
    texts &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join(word &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; word &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; word_filtered)
    cloud &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; WordCloud(max_font_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;, max_words&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, background_color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;white&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;generate(texts)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(cloud, interpolation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bilinear&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# plot wordcloud for Man&lt;/span&gt;
plot_wordcloud(males, &lt;span style=&#34;color:#ae81ff&#34;&gt;24&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# 24 specifies the column number&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[(&#39;me&#39;, 2), (&#39;adjust&#39;, 2), (&#39;overall&#39;, 2), (&#39;personal&#39;, 2), (&#39;im&#39;, 2), (&#39;its&#39;, 1), (&#39;used&#39;, 1), (&#39;simply&#39;, 1), (&#39;interests&#39;, 1), (&#39;food&#39;, 1)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./TextualDataAnalysis_42_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# plot wordcloud for Woman&lt;/span&gt;
plot_wordcloud(females, &lt;span style=&#34;color:#ae81ff&#34;&gt;24&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[(&#39;use&#39;, 4), (&#39;see&#39;, 4), (&#39;im&#39;, 4), (&#39;bit&#39;, 3), (&#39;more&#39;, 3), (&#39;less&#39;, 3), (&#39;food&#39;, 3), (&#39;know&#39;, 3), (&#39;sleep&#39;, 2), (&#39;information&#39;, 2)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./TextualDataAnalysis_43_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;The top image is the wordcloud of male participants and the bottom is that of female participants. We see that some words are not as meaningful and that one critical fault to this approach is that breaking down the responses into word level can misrepresent the meaning of their responses. For example, &amp;lsquo;exercise&amp;rsquo; and &amp;lsquo;not exercise&amp;rsquo; have two opposing ideas but here, it would count &amp;lsquo;not&amp;rsquo; and &amp;lsquo;exercise&amp;rsquo; as two seperate ideas.&lt;/p&gt;
&lt;p&gt;Even though the word counts are small, we see more &amp;lsquo;food&amp;rsquo; and &amp;lsquo;sleep&amp;rsquo; for female participants, leading to an assumption that it could be related to going on diets.&lt;/p&gt;
&lt;h3 id=&#34;analyzing-categorical-data-using-wordcloud&#34;&gt;Analyzing categorical data using wordcloud&lt;/h3&gt;
&lt;p&gt;Participants were also asked, &amp;ldquo;what actions do you take regarding your health?&amp;rdquo; with multiple choices answer selections that include&amp;hellip;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&amp;lsquo;exercise&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;take medication or health supplements&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;track health or fitness&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;learn more about health&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;receive regular treatment at clinic&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;maintain a diet&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;receive mental counseling.&amp;rsquo;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plot_wordcloud(males, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;;&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[(&#39;exercise&#39;, 29), (&#39;take medication and/or health supplements&#39;, 10), (&#39;track your health and/or fitness&#39;, 9), (&#39;learn more about your health (eg from online friends or community)&#39;, 8), (&#39;maintain a diet&#39;, 8), (&#39;receive regular treatment and/or consultation at clinic&#39;, 3), (&#39;none of the above&#39;, 2)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./TextualDataAnalysis_46_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plot_wordcloud(females, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;;&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[(&#39;exercise&#39;, 30), (&#39;take medication and/or health supplements&#39;, 27), (&#39;track your health and/or fitness&#39;, 24), (&#39;learn more about your health (eg from online friends or community)&#39;, 17), (&#39;receive regular treatment and/or consultation at clinic&#39;, 17), (&#39;maintain a diet&#39;, 16), (&#39;receive mental counseling&#39;, 7)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./TextualDataAnalysis_47_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;From the two results above, we see that exercise is the most common practice for keeping up health in both genders. However, we see that in general, women tend to do more activities or attempts to maintain their health e.g. by more frequently visiting a clinic or receive counseling, whereas two men responded they simply do nothing at all.&lt;/p&gt;
&lt;hr&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;a-namelink9-conclusion--thoughts-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; Conclusion &amp;amp; Thoughts &lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;Wordcloud is a fun, engaging representation of textual data. However, more caution and consideration are needed because it can also tweak how the data is represented. For example, I coded the function so that it would breakdown any sentences or phrases into word level. This means that if someone does &amp;lsquo;not exercise&amp;rsquo;, it would still count &amp;lsquo;exercise&amp;rsquo; and the end result would show &amp;lsquo;exercise&amp;rsquo; being emphasized more. While the context of exercise is present, the meaning is totally the opposite.&lt;/p&gt;
&lt;hr&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;GoogleSheets API v4: &lt;a href=&#34;https://developers.google.com/sheets/api/samples/reading&#34;&gt;https://developers.google.com/sheets/api/samples/reading&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Google Oauth: &lt;a href=&#34;https://developers.google.com/identity/protocols/oauth2/service-account#python&#34;&gt;https://developers.google.com/identity/protocols/oauth2/service-account#python&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Google API Python Client: &lt;a href=&#34;https://github.com/googleapis/google-api-python-client/blob/master/docs/oauth.md&#34;&gt;https://github.com/googleapis/google-api-python-client/blob/master/docs/oauth.md&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Credentials: &lt;a href=&#34;https://developers.google.com/workspace/guides/create-credentials&#34;&gt;https://developers.google.com/workspace/guides/create-credentials&lt;/a&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>Statistical Data Analysis in Cross-Cultural Research</title>
      <link>https://jinjeon.me/post/quant-ux/</link>
      <pubDate>Mon, 22 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://jinjeon.me/post/quant-ux/</guid>
      <description>&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;I use survey data collected from Amazon Mechanical Turk and Reddit user groups (all personal data  have been removed) in a study to examine the impact of cultural localization on web-based account creation between American and Korean users. I use the experiment data to display basic statistical tests in Python.&lt;/p&gt;
&lt;h3 id=&#34;research-question&#34;&gt;Research Question:&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Is there a difference in providing personal information between USA and Korean Internet users &lt;!-- raw HTML omitted --&gt;
within two different use scenarios: online banking and shopping?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I use the following tests:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;#link1&#34;&gt;Pearson Correlation Coefficient&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;#link2&#34;&gt;T-Test&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;#link3&#34;&gt;Mann-Whitney Test&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;#link4&#34;&gt;One-Way Analysis of Variance (ANOVA)&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;#link5&#34;&gt;Two-Way ANOVA&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; sns
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; scipy
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; matplotlib &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pyplot
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; statsmodels.formula.api &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ols
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; statsmodels.formula.api &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; smf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; statsmodels.api &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; sm
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; statsmodels.stats.anova &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; AnovaRM
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pdb  &lt;span style=&#34;color:#75715e&#34;&gt;# for debugging&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; warnings
warnings&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;simplefilter(action&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ignore&amp;#39;&lt;/span&gt;, category&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;FutureWarning&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# set color&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_color_codes(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pastel&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;setup--querying-data&#34;&gt;Setup &amp;amp; Querying Data&lt;/h2&gt;
&lt;p&gt;It is first critical to understand the dataframe to play around and make analysis. Usually, &lt;strong&gt;&lt;em&gt;long-format&lt;/em&gt;&lt;/strong&gt; data is desired (or at least I&amp;rsquo;m used to it) for using Python and Seaborn for data visualization. Long format is basically when each variable is represented as a column, and each observation or event is a row. Below, we read in, and query the data.&lt;/p&gt;
&lt;h4 id=&#34;useful-commands&#34;&gt;Useful commands:&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;df.head()&lt;/code&gt;: by default, shows first five rows of df&lt;/li&gt;
&lt;li&gt;&lt;code&gt;df.columns()&lt;/code&gt;: prints all the columns in df&lt;/li&gt;
&lt;li&gt;&lt;code&gt;df.describe()&lt;/code&gt;: provides summary description of df&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pd.read_csv(data, usecols=[&#39;col1&#39;, &#39;col2&#39;, ...,])&lt;/code&gt;: can be used to filter columns&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# read in data.csv file as df &amp;amp; see data structure&lt;/span&gt;
df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;data.csv&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# query data by scenario and culture&lt;/span&gt;
bank &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;scenario == &amp;#39;Bank&amp;#39;&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;copy()
shop &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;scenario == &amp;#39;Shop&amp;#39;&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;copy()
kor &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;culture == &amp;#39;Korea&amp;#39;&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;copy()
usa &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;culture == &amp;#39;USA&amp;#39;&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;copy()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# an example of the data structure&lt;/span&gt;
usa&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;!-- raw HTML omitted --&gt;
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;hr&gt;
&lt;h2 id=&#34;a-namelink1-1-pearson-correlation-coefficient-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; 1. Pearson Correlation Coefficient &lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;When we want to ask &lt;em&gt;&amp;ldquo;how strongly correlated are the two variables?&amp;quot;&lt;/em&gt;, we can use &lt;strong&gt;Perason&amp;rsquo;s Correlation&lt;/strong&gt;. It is used to measure statistical relationship or association between two &lt;strong&gt;&lt;em&gt;continuous variables&lt;/em&gt;&lt;/strong&gt; that are linearly related to each other. The coefficient value &lt;em&gt;&amp;ldquo;r&amp;rdquo;&lt;/em&gt; ranges from -1 (negative relation) to 1 (perfectly positive). 0 would mean that there is no relationship at all.&lt;/p&gt;
&lt;h3 id=&#34;properties-of-pearson-correlation&#34;&gt;Properties of Pearson Correlation&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;The units of the values do not affect the Pearson Correlation.
&lt;ul&gt;
&lt;li&gt;i.e. Changing the unit of value from cm to inches do not affect the r value&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The correlation between the two variables is symmetric:
&lt;ul&gt;
&lt;li&gt;i.e. A -&amp;gt; B is equal to B -&amp;gt; A&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;** Use &lt;strong&gt;&lt;em&gt;Spearman&amp;rsquo;s Correlation&lt;/em&gt;&lt;/strong&gt; when the two variables have non-linear relationship (e.g. a curve instead of a straight line).&lt;/p&gt;
&lt;h3 id=&#34;code-implementation&#34;&gt;Code Implementation&lt;/h3&gt;
&lt;p&gt;We use scipy package to calculate the Pearson Correlation. The method will return two values: &lt;strong&gt;&lt;em&gt;r&lt;/em&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;em&gt;p&lt;/em&gt;&lt;/strong&gt; value.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# let&amp;#39;s look at the correlation of information provided by different scenarios: online banking vs. shopping&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# bank[&amp;#39;percent&amp;#39;] will return an array of percentage values&lt;/span&gt;

r, p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; scipy&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pearsonr(bank[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;percent&amp;#39;&lt;/span&gt;], shop[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;percent&amp;#39;&lt;/span&gt;])  
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r: &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(r&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;round(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)))
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;p: &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;round(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;r: 0.7592
p: 0.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the results above, we can see &lt;strong&gt;there is a strong positive relationship between the amount of information provided in banking and shopping.&lt;/strong&gt; i.e. Providing information in banking would affect how a user provides personal information in shopping.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;a-namelink2-2-t-test-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; 2. T-Test &lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;When comparing the means of two groups, we can use a &lt;strong&gt;t-test&lt;/strong&gt;. It takes into account of the means and the spread of the data to determine &lt;strong&gt;&lt;em&gt;whether a difference between the two would occur by chance or not&lt;/em&gt;&lt;/strong&gt; (determined by the p-value being less than 0.05 usually). In a t-test, there should be only two independent variables (categorical/nominal variables) and one dependent continuous variable.&lt;/p&gt;
&lt;h3 id=&#34;properties-of-t-test&#34;&gt;Properties of t-test&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The data is assumed to be &lt;strong&gt;normal&lt;/strong&gt; (If the distribution is skewed, use Mann-Whitney test). &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;T-test yields &lt;strong&gt;&lt;em&gt;t&lt;/em&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;em&gt;p&lt;/em&gt;&lt;/strong&gt; value:&lt;!-- raw HTML omitted --&gt;
2a. &lt;strong&gt;The higher the t, the more difference there is between the two groups.&lt;/strong&gt; The lower the t, the more similar the two groups are.&lt;!-- raw HTML omitted --&gt;
2b. T-value of 2 means the groups are twice as different from each other than they are within each other&lt;!-- raw HTML omitted --&gt;
2c. &lt;strong&gt;The lower the p-value, the better&lt;/strong&gt; (meaning that it is significant and the difference did not occure by chance). P-value of 0.05 means that there is 5 percent happening by chance&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;code-implementation-1&#34;&gt;Code Implementation&lt;/h3&gt;
&lt;p&gt;We use scipy package again to run a t-test. Before we decide which test to run, we can quickly plot and see the distribution like below.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(df[df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;scenario&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Bank&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;percent)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;matplotlib.axes._subplots.AxesSubplot at 0x1c238f61d0&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./output_10_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;The distribution looks relatively normal. We can run a t-test to see whether there is a difference between the total amount of information provided by the users from each use scenario: i.e. banking vs. shopping&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# we run a t-test to see whether there ia a difference in the amount of information provided in each scenario&lt;/span&gt;
t, p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; scipy&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ttest_ind(df[df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;scenario&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Bank&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;percent, df[df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;scenario&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Shop&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;percent)
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;t: &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;round(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)))
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;p: &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;round(&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;t: 4.8203
p: 2e-06
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result above shows that there is a significant difference in the amount of information provided between two use scenarios with t-value being high, and p-value being very small. However, we don&amp;rsquo;t actually know which scenario yields more information than the other. The t-test only tells there is a significant difference.&lt;/p&gt;
&lt;p&gt;To find out, we can create a little fancy distribution plot with some box plots:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;banking &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;scenario&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Bank&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;percent
shopping &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;scenario&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Shop&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;percent

&lt;span style=&#34;color:#75715e&#34;&gt;# let&amp;#39;s plot box-dist plot combined&lt;/span&gt;
f, (ax_box1, ax_box2, ax_dist) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, sharex&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;,
                                              gridspec_kw&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;height_ratios&amp;#34;&lt;/span&gt;: (&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)})

&lt;span style=&#34;color:#75715e&#34;&gt;# add boxplots at the top&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;boxplot(banking, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax_box1, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g&amp;#39;&lt;/span&gt;)
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;boxplot(shopping, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax_box2, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;m&amp;#39;&lt;/span&gt;)
ax_box1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(banking), color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g&amp;#39;&lt;/span&gt;, linestyle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--&amp;#39;&lt;/span&gt;)
ax_box2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(shopping), color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;m&amp;#39;&lt;/span&gt;, linestyle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots_adjust(top&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.87&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;suptitle(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Amount of information provided by use scenario&amp;#39;&lt;/span&gt;, fontsize &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;17&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# add distplots below&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(banking, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax_dist, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Banking&amp;#39;&lt;/span&gt;, kde&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, rug&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g&amp;#39;&lt;/span&gt;, norm_hist&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, bins&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(shopping, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax_dist, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Shopping&amp;#39;&lt;/span&gt;, kde&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, rug&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;m&amp;#39;&lt;/span&gt;, norm_hist&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, bins&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)

ax_dist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(banking), color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g&amp;#39;&lt;/span&gt;, linestyle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--&amp;#39;&lt;/span&gt;)
ax_dist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(shopping), color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;m&amp;#39;&lt;/span&gt;, linestyle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Percentage of information&amp;#39;&lt;/span&gt;, fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;)
ax_box1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set(xlabel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;)
ax_box2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set(xlabel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[Text(0.5, 0, &#39;&#39;)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./output_14_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;From the graph above, we see that the mean of the banking is greater than the mean of shopping. This shows us that regardless of cultural background, users are more likely to provide personal information in the banking scenario.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;a-namelink3-3-mann-whitney-test-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; 3. Mann-Whitney Test &lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;The Mann-Whitney Test allows you to determine if the observed difference is statistically significant without making the assumption that the values are normally distributed. You should have two independent variables and one continuous dependent variable.&lt;/p&gt;
&lt;h3 id=&#34;code-implementation-2&#34;&gt;Code Implementation&lt;/h3&gt;
&lt;p&gt;We can run the test on the same banking vs. shopping scenario.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;t, p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; scipy&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mannwhitneyu(df[df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;scenario&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Bank&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;percent, df[df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;scenario&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Shop&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;percent)
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;t: &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;round(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)))
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;p: &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;round(&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;t: 14795.5
p: 4.1e-05
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;a-namelink4-4-one-way-analysis-of-variance-anova-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; 4. One-Way Analysis of Variance (ANOVA) &lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;ANOVA is similar to a t-test, but it is used when there are three or more independent variables (categorical). It assumes normal distribution (use Kruskal-Wallis if abnormal?). One-way ANOVA compares the means between the variables to test whether the difference is statistically significant. However, it does not tell you which specific groups were statistically different from one another. Thus, a post-hoc analysis is required.&lt;/p&gt;
&lt;h3 id=&#34;code-implementation-3&#34;&gt;Code Implementation&lt;/h3&gt;
&lt;p&gt;The result below suggests that there is a statistical difference in the means of the three variables.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# we can create a third variable, and compare the var1, var2, and var3 with one-way ANOVA&lt;/span&gt;
var3 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;culture&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;USA&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;percent
scipy&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;f_oneway(banking, shopping, var3)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;F_onewayResult(statistic=11.171874914065159, pvalue=1.7072783704546878e-05)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;a-namelink5-5-two-way-anova-a&#34;&gt;&lt;!-- raw HTML omitted --&gt; 5. Two-Way ANOVA &lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;A two-way ANOVA can be used when you want to know how two independent variables have an interaction effect on a dependent variable. CAVEAT: a two-way ANOVA does not tell which variable is dominant.&lt;/p&gt;
&lt;h3 id=&#34;code-implementation-4&#34;&gt;Code Implementation&lt;/h3&gt;
&lt;p&gt;Below in the code, we see &lt;strong&gt;&lt;em&gt;if there is an interaction effect between culture and scenario use cases on the total amount of information provided.&lt;/em&gt;&lt;/strong&gt; For example, would Americans be more willing to provide personal information than Koreans? If so, does the use case (either banking vs. shopping) affect at all?&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# we give in a string value of each variable, and the interaction variable &amp;#39;culture:scenario&amp;#39;&lt;/span&gt;

model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ols(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;percent ~ culture + scenario + culture:scenario&amp;#39;&lt;/span&gt;, data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;df)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit()
sm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;anova_lm(model, typ&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;!-- raw HTML omitted --&gt;
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;From the table above, only scenario has a sole effect on the total amount of information provided (depicted as &lt;code&gt;percent&lt;/code&gt; in the dataframe). We see culture, and the interaction of culture and scenario do not have an effect on the amount of information that users provided.&lt;/p&gt;
&lt;p&gt;The finding matches with the previous t-test and graph results, where users provided more information in the banking than they would in shopping.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>Information Theory: Mutual Information</title>
      <link>https://jinjeon.me/post/mutual-info/</link>
      <pubDate>Fri, 31 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://jinjeon.me/post/mutual-info/</guid>
      <description>&lt;h2 id=&#34;entropy-in-neuroimaging&#34;&gt;Entropy in Neuroimaging&lt;/h2&gt;
&lt;p&gt;Entropy has three interpretations (three are identical, but in different expressions &amp;amp; relations):&lt;/p&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;1. Amount of information in an event (N of possible outcomes, or grey value in images)&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The larger the number of possible outcomes, the larger the information gain
&lt;ul&gt;
&lt;li&gt;Ex. Information gain from a sentence would exponentially increase with length of sentence&lt;!-- raw HTML omitted --&gt;&lt;/li&gt;
&lt;li&gt;If outcome is 1, information gain is 0 (i.e. log1 = 0)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;2. Uncertainty of outcome in an event&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Amount of information gain with probability is inversely related to the probability that the event will take place. The information per event is weighted by the probability of the event&lt;!-- raw HTML omitted --&gt;&lt;/li&gt;
&lt;li&gt;The rarer an event, the more significance the event has&lt;/li&gt;
&lt;li&gt;When all events are likely to occur, uncertainty or entropy is maximum (ie. more possible outcomes)&lt;/li&gt;
&lt;li&gt;Most common entropy form is the Shannon&amp;rsquo;s entropy:
\begin{equation*}
H = \sum_{i} p_i log(p_i)
\end{equation*}&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Entropy Example&lt;/strong&gt; &lt;!-- raw HTML omitted --&gt;
&amp;gt;  In a fair coin toss, entropy is maximum. Vice versa, the more unfair the coint toss is, the more definitive the outcome is (which means lower entropy)&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;
&amp;gt;  Fair coin toss: P(head) = 0.5, P(tail) = 0.5&lt;!-- raw HTML omitted --&gt;
&amp;gt;  Entropy = -0.5log0.5 - 0.5log0.5 = 0.150 + 0.150 = 0.300
&amp;gt;&lt;br&gt;
&amp;gt;  Unfair coin toss: P(head) = 0.8, P(tail) = 0.2&lt;!-- raw HTML omitted --&gt;
&amp;gt;  Entropy = -0.8log0.8 - 0.2log0.2 = 0.077 + 0.140 = 0.217&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;3. Dispersion of probability distribution&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Shannon&amp;rsquo;s entropy can be used as a measure of dispersion of a probability distribution. It can be computed on images by looking at their dispersion of grey values&lt;/li&gt;
&lt;li&gt;Image with single intensity will have low entropy value as it contains little information. Conversely, if image with varying intesity will have higher entropy value with more information&lt;/li&gt;
&lt;li&gt;Ex. image with single sharp peak (ie. grey value condensed in small area) will have low entropy value&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;mutual-information&#34;&gt;Mutual Information&lt;/h2&gt;
&lt;p&gt;The goal of registration is to maximize mutual information or the overlaps. There are three ways of interpreting MI, in which they are identical but in different forms of expression and relation of variables.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;I(X, Y) = H(Y) - H(Y | X)&lt;/em&gt;&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;This is the most closest form of mutual information. ie. MI of X and Y is subtracting entropy of H(Y) from the conditional entropy H(Y|X) (or p(Y) given p(X): chance of grey value in B given that corresponding image in A has grey value).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In expression of uncertainty, MI is the amount by which uncertainty about Y changes when the amount of X containing Y is given
&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;I(X, Y) = H(X) + H(Y) - H(X, Y)&lt;/em&gt;&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;It is the most closest form to joint entropy. &lt;em&gt;H(X | Y)&lt;/em&gt; tells us that mutual information is greater when the joint entropy is lower. Small entropy or less dispersion would mean that information overlaps more.&lt;br&gt;
&lt;!-- raw HTML omitted --&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;I(X, Y) = Sum of [p(x,y) log (p(x,y) / p(x)p(y))&lt;/em&gt;&lt;/strong&gt;]
&lt;ul&gt;
&lt;li&gt;This formula is analogous to Kullback-Leibler distance, which measures the distance between two distributions. It measures the dependence of the two images by calculating the distance between the joint distribution of the image&amp;rsquo;s grey values p(x,y) and the joint distribution in case of independence of the two images p(x)p(y)&lt;/li&gt;
&lt;li&gt;We will use this formula to measure MI later in the code&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;code-implementation&#34;&gt;Code Implementation&lt;/h2&gt;
&lt;p&gt;Now let&amp;rsquo;s try using Python to measure mutual information of given images. We will be mainly comparing in two ways: comparing the identical images, and two different images.&lt;/p&gt;
&lt;h4 id=&#34;1-lets-begin-with-a-setup-and-direct-the-image-files&#34;&gt;1. Let&amp;rsquo;s begin with a setup, and direct the image files&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; __future__ &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; division
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; nibabel &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; nib

&lt;span style=&#34;color:#75715e&#34;&gt;# set gray colormap and nearest neighbor interpolation by default&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rcParams[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;image.cmap&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rcParams[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;image.interpolation&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;nearest&amp;#39;&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# set the images&lt;/span&gt;
os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;chdir(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/Users/Jin/Documents/MATLAB&amp;#39;&lt;/span&gt;)

img1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;4_23_Drake.nii&amp;#39;&lt;/span&gt;
img2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;4_24_Denzel_Washington.nii&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;2-lets-slice-the-image-and-set-side-by-side-to-display&#34;&gt;2. Let&amp;rsquo;s slice the image and set side by side to display&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_img_slice&lt;/span&gt;(img, size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    load the image using nibabel and slice the image by given size
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Parameters
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    ----------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    img: nii image data read via nibabel
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Returns
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    -------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    numpy memmap: ndarray of image slice
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    img_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nib&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load(img)
    img_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img_data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_data()
    img_slice &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img_data[:, :, size]  &lt;span style=&#34;color:#75715e&#34;&gt;# 50 is arbitrary here&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# convert any nans to 0s&lt;/span&gt;
    img_nans &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;isnan(img_slice)
    img_slice[img_nans] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; img_slice

img1_slice &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_img_slice(img1)
img2_slice &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_img_slice(img2)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# display images left and right&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;plot_raw&lt;/span&gt;(img1, img2):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hstack((img1, img2)))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

plot_raw(img1_slice, img1_slice)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./mutual_information_neuroimaging_6_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;3-lets-plot-a-1d-histogram-for-each-of-the-two-iamges&#34;&gt;3. Let&amp;rsquo;s plot a 1d histogram for each of the two iamges&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;plot_hist1d&lt;/span&gt;(img1, img2, bins&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    one dimensional histogram of the slices
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Parameters
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    ----------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    img1: nii image data read via nibabel
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    img2: nii image data read via nibabel
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    bins: optional (default=20)
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        bin size of the histogram
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Returns
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    -------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    histogram
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        comparing two images side by side
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    fig, axes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
    axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hist(img1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ravel(), bins)
    axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Img1 histogram&amp;#39;&lt;/span&gt;)
    axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hist(img2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ravel(), bins)
    axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Img2 histogram&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plot_hist1d(img1_slice, img2_slice)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./mutual_information_neuroimaging_9_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;4-lets-plot-the-two-images-against-each-other-on-a-scatter-plot-and-calculate-correlation-coefficient&#34;&gt;4. Let&amp;rsquo;s plot the two images against each other on a scatter plot, and calculate correlation coefficient&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;plot_scatter2d&lt;/span&gt;(img1, img2):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    plot the two image&amp;#39;s histogram against each other
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Parameters
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    ----------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    img1: nii image data read via nibabel
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    img2: nii image data read via nibabel
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Returns
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    -------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    2d plotting of the two images and correlation coeeficient
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    corr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;corrcoef(img1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ravel(), img2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ravel())[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(img1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ravel(), img2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ravel(), &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.&amp;#39;&lt;/span&gt;)

    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Img1 signal&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Img2 signal&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Img1 vs Img2 signal cc=&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(corr))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# this one is comparing two identical images so it should equal 1&lt;/span&gt;
plot_scatter2d(img1_slice, img1_slice)

&lt;span style=&#34;color:#75715e&#34;&gt;# image 1 vs image 2&lt;/span&gt;
plot_scatter2d(img1_slice, img2_slice)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./mutual_information_neuroimaging_12_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./mutual_information_neuroimaging_12_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;feature-space&#34;&gt;Feature Space&lt;/h3&gt;
&lt;p&gt;Using MI as a registration measure, we plot a &lt;strong&gt;&lt;em&gt;feature space&lt;/em&gt;&lt;/strong&gt; (or &lt;strong&gt;&lt;em&gt;joint histogram&lt;/em&gt;&lt;/strong&gt;), a two-dimensional plot showing the combinations of grey values in each of the two images for all corresponding points. For example, for each corresponding point (x, y), in which x and y are coordinates of first and second images respectively,&lt;/p&gt;
&lt;p&gt;As the alignment of the two images change, the feature space changes. The more correctly registered the two images are, the more anatomical structures will overlap, showing clusters for the grey values. When the images are misaligned, the intensity of the clusters for certain structures will decrease, and a new pair of (x, y) will be matched as the image gets incorrectly aligned with other nearby structures of the other image. This is be shown as the dispersion of the clustering.&lt;/p&gt;
&lt;h4 id=&#34;5-lets-plot-a-joint-histogram-now&#34;&gt;5. Let&amp;rsquo;s plot a joint histogram now&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;plot_joint_histogram&lt;/span&gt;(img1, img2, bins&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;, log&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    plot feature space. Given two images, the feature space is constructed by counting the number of times a combination of grey values occur
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Parameters
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    ----------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    img1: nii image data read via nibabel
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    img2: nii image data read via nibabel
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    bins: optional (default=20)
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        bin size of the histogram
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    log: boolean (default=True)
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        keeping it true will show a better contrasted image
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Returns
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    -------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    joint histogram
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        feature space of the two images in graph
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    hist_2d, x_edges, y_edges &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;histogram2d(img1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ravel(), img2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ravel(), bins)
    &lt;span style=&#34;color:#75715e&#34;&gt;# transpose to put the T1 bins on the horizontal axis and use &amp;#39;lower&amp;#39; to put 0, 0 at the bottom of the plot&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; log:
        plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(hist_2d&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T, origin&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lower&amp;#39;&lt;/span&gt;)
        plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Img1 signal bin&amp;#39;&lt;/span&gt;)
        plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Img2 signal bin&amp;#39;&lt;/span&gt;)

    &lt;span style=&#34;color:#75715e&#34;&gt;# log the values to reduce the bins with large values&lt;/span&gt;
    hist_2d_log &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros(hist_2d&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
    non_zeros &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; hist_2d &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    hist_2d_log[non_zeros] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log(hist_2d[non_zeros])
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(hist_2d_log&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T, origin&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lower&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Img1 signal bin&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Img2 signal bin&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# this should print a linear graph as it&amp;#39;s comparing it to itself&lt;/span&gt;
print(plot_joint_histogram(img1_slice, img1_slice))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;None
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./mutual_information_neuroimaging_15_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# compare images 1 and 2&lt;/span&gt;
print(plot_joint_histogram(img1_slice, img2_slice))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;None
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./mutual_information_neuroimaging_16_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;6-lets-calculate-the-mutual-information-of-the-two-images-now&#34;&gt;6. Let&amp;rsquo;s calculate the mutual information of the two images now.&lt;/h4&gt;
&lt;p&gt;We use the third formula stated above to measure the overlaps of the two images. The goal of registration is to maximize mutual information or the overlaps.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mutual_information&lt;/span&gt;(img1, img2, bins&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    measure the mutual information of the given two images
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Parameters
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    ----------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    img1: nii image data read via nibabel
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    img2: nii image data read via nibabel
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    bins: optional (default=20)
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        bin size of the histogram
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Returns
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    -------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    calculated mutual information: float
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    hist_2d, x_edges, y_edges &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;histogram2d(img1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ravel(), img2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ravel(), bins)

    &lt;span style=&#34;color:#75715e&#34;&gt;# convert bins counts to probability values&lt;/span&gt;
    pxy &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; hist_2d &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; float(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(hist_2d))
    px &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(pxy, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# marginal x over y&lt;/span&gt;
    py &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(pxy, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# marginal y over x&lt;/span&gt;
    px_py &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; px[:, &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; py[&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;, :]  &lt;span style=&#34;color:#75715e&#34;&gt;# broadcast to multiply marginals&lt;/span&gt;

    &lt;span style=&#34;color:#75715e&#34;&gt;# now we can do the calculation using the pxy, px_py 2D arrays&lt;/span&gt;
    nonzeros &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pxy &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# filer out the zero values&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(pxy[nonzeros] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log(pxy[nonzeros] &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; px_py[nonzeros]))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# the MI value of the first should be greater than the second as the first is comparing the image to itself&lt;/span&gt;
print(mutual_information(img1_slice, img1_slice))
print(mutual_information(img1_slice, img2_slice))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;1.1967155090861803
0.20578049748917815
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;calculating-the-grand-average-of-mutual-information&#34;&gt;Calculating the Grand Average of Mutual Information&lt;/h2&gt;
&lt;p&gt;The codes above are detailed step-by-step processes. We can condense the codes above into one useful function that will allow us to examine the overall average of mutual information of each every scan image to the register image.&lt;/p&gt;
&lt;p&gt;For example, given a register type (&amp;lsquo;rtf&amp;rsquo; for register to first image, or &amp;lsquo;rtm&amp;rsquo; for register to mean), it will calculate each scan to the register image, calculate the MI, and return the grand average MI value.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The code is currently based on ACCRE system so the paths directing to the images must be changed for flexible use. The path should direct to the folder which holds all the scan images, and since it requires gigabytes of data, I had to implement the code on ACCRE-use only.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_avg_mi&lt;/span&gt;(subjID, type&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rtf&amp;#39;&lt;/span&gt;, saveText&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;, nScans&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;187&lt;/span&gt;):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    calculates the correlation coefficient and mutual information of the registered image to the rest of image files, and returns the grand average and trial averages
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Parameters
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    ----------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    subjID : str
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        string of subject data (ie. &amp;#39;cdcatmr011&amp;#39;)
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    type : str {&amp;#39;rtf&amp;#39;, &amp;#39;rtm&amp;#39;}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        registration type that would either register to first scan image or the mean image (default: &amp;#39;rtf&amp;#39;)
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    saveText : boolean
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        if True, will save the table report to a separate text file (default: False)
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    verbose : boolean
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        if True, will print out which scan file is being worked on (default: False)
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    nScans : int
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        integer of how many scans to expect per each run (default: 187)
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Returns
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    -------
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    cc_all: list
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        list of all correlation coefficient values
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    mi_all: list
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        list of all mutual information values
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    saveText &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;
    subj &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; str(subjID)
    baseDir &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/scratch/polynlab/fmri/cdcatmr/&amp;#39;&lt;/span&gt;
    funcDir &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; baseDir &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; subj &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/images/func&amp;#39;&lt;/span&gt;
    tag &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;func&amp;#39;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; type &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rtf&amp;#39;&lt;/span&gt;:  &lt;span style=&#34;color:#75715e&#34;&gt;# register to first&lt;/span&gt;
        sourceImg &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/func1/func1_00001.nii&amp;#39;&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# [rmeanfunc1_00001.nii, meanfunc1_00001.nii]&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# tag = &amp;#39;func&amp;#39;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; type &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rtm&amp;#39;&lt;/span&gt;:  &lt;span style=&#34;color:#75715e&#34;&gt;# register to mean&lt;/span&gt;
        sourceImg &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/func1/meanfunc1_00001.nii&amp;#39;&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# tag = &amp;#39;rfunc&amp;#39;&lt;/span&gt;
    resDir &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/home/jeonj1/proj/mi&amp;#39;&lt;/span&gt;

    os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;chdir(funcDir)
    funcs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;listdir(funcDir)
    funcs&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sort()  &lt;span style=&#34;color:#75715e&#34;&gt;# funcs = [&amp;#39;func1&amp;#39;, &amp;#39;func2&amp;#39;, ... &amp;#39;func7&amp;#39;, &amp;#39;func8&amp;#39;]&lt;/span&gt;

    meanImg &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mi&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_img_slice(funcDir &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; sourceImg, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;verbose)
    mi_listVar &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    cc_listVar &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    &lt;span style=&#34;color:#75715e&#34;&gt;# loop by each functional run&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(funcs)):
        curr_func &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; funcs[i]
        &lt;span style=&#34;color:#75715e&#34;&gt;# let&amp;#39;s first create list variables for each functional run&lt;/span&gt;
        temp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;
        temp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mi_&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; curr_func &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; = []&amp;#39;&lt;/span&gt;
        exec(temp)
        mi_listVar&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mi_&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; curr_func)
        temp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;
        temp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cc_&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; curr_func &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; = []&amp;#39;&lt;/span&gt;
        exec(temp)
        cc_listVar&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cc_&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; curr_func)

        &lt;span style=&#34;color:#75715e&#34;&gt;# now let&amp;#39;s read in each functional run folder&lt;/span&gt;
        cfuncDir &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; funcDir &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; curr_func
        os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;chdir(cfuncDir)
        nii_files &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;listdir(cfuncDir)
        nii_files &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [x &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; nii_files &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;startswith(tag) &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;endswith(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;nii&amp;#39;&lt;/span&gt;)]
        nii_files&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sort()

        &lt;span style=&#34;color:#75715e&#34;&gt;# sanity check: count scan files&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;assert&lt;/span&gt; len(nii_files) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; nScans, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;total scan files found do not match &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(nScans) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; for func run &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

        &lt;span style=&#34;color:#75715e&#34;&gt;# loop by each scan within run&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, nScans):
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; verbose:
                print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;starting &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; curr_func &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; | scan &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(j&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
            curr_nii &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mi&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_img_slice(nii_files[j], verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;verbose)
            corr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mi&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_core(meanImg, curr_nii)
            mutual_info &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mi&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mutual_information(meanImg, curr_nii)

            &lt;span style=&#34;color:#75715e&#34;&gt;# append each list&lt;/span&gt;
            temp_cc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cc_&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; curr_func &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.append(corr)&amp;#39;&lt;/span&gt;
            exec(temp_cc)
            temp_mi &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mi_&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; curr_func &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.append(mutual_info)&amp;#39;&lt;/span&gt;
            exec(temp_mi)

    cc_sums &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    mi_sums &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; r &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(funcs)):
        cc_sums&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(sum(eval(cc_listVar[r])))
        mi_sums&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(sum(eval(mi_listVar[r])))

    &lt;span style=&#34;color:#75715e&#34;&gt;# get all entries in a single list&lt;/span&gt;
    cc_all &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    mi_all &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; r &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(funcs)):
        cc_all &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cc_all &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; eval(cc_listVar[r])
        mi_all &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mi_all &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; eval(mi_listVar[r])


    reports &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    reports&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;avg cc&amp;#39;&lt;/span&gt;, sum(cc_sums)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(nScans&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;len(funcs))])
    reports&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;avg mi&amp;#39;&lt;/span&gt;, sum(mi_sums)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(nScans&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;len(funcs))])
    reports&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cc by runs&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;-----&amp;#39;&lt;/span&gt;])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; l &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; cc_listVar:
        reports&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append([l, sum(eval(l))&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;nScans])
    reports&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mi by runs&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;-----&amp;#39;&lt;/span&gt;])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; l &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; mi_listVar:
        reports&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append([l, sum(eval(l))&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;nScans])

    print(tabulate(reports))

    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; saveText:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; open(resDir &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; subj &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;_mi_&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;basename(sourceImg) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.txt&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;w&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; f:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; item &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; reports:
                f&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;write(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; item)
        print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;saved the table report to &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; resDir)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; cc_all, mi_all

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;t-test-and-plotting&#34;&gt;T-test and Plotting&lt;/h2&gt;
&lt;p&gt;We can use the function &lt;code&gt;get_avg_mi&lt;/code&gt; above to calculate the grand average. Then we will run a t-test on the two averages and plot the differences for visual reference. The script below is currently somewhat hard coded for simplicity sake.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;nScans &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;187&lt;/span&gt;
nRuns &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# we use the get_avg_mi function stated above. Specify the subject and register type.&lt;/span&gt;
cc1, mi1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_avg_mi(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cdcatmr066&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rtf&amp;#39;&lt;/span&gt;, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# register to first scan&lt;/span&gt;
cc2, mi2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_avg_mi(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cdcatmr066&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rtm&amp;#39;&lt;/span&gt;, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# register to mean&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;assert&lt;/span&gt; len(cc1) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; len(cc2) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; nScans &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; nRuns
&lt;span style=&#34;color:#66d9ef&#34;&gt;assert&lt;/span&gt; len(mi1) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; len(mi2) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; nScans &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; nRuns

cc_t, cc_p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ttest_ind(cc1, cc2)
mi_t, mi_p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ttest_ind(mi1, mi2)


&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; sns
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#75715e&#34;&gt;# switch matplotlib backend so that it knows it won&amp;#39;t print anything.&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;switch_backend(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;agg&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# sns.set(color_codes=True)&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_color_codes(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pastel&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# sns.set_palette(&amp;#34;tab10&amp;#34;)&lt;/span&gt;

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(cc1, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rtf&amp;#39;&lt;/span&gt;);
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(cc2, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rtm&amp;#39;&lt;/span&gt;);
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;correlation coefficient n=&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(len(cc1)))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;savefig(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/home/jeonj1/proj/mi/cc_distplot.png&amp;#39;&lt;/span&gt;)

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(mi1, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rtf&amp;#39;&lt;/span&gt;);
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(mi2, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rtm&amp;#39;&lt;/span&gt;);
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mutual info | n=&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(len(mi1)))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;savefig(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/home/jeonj1/proj/mi/mi_distplot.png&amp;#39;&lt;/span&gt;)


&lt;span style=&#34;color:#75715e&#34;&gt;# let&amp;#39;s plot box-dist plot combined&lt;/span&gt;
f, (ax_box1, ax_box2, ax_dist) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, sharex&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, gridspec_kw&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;height_ratios&amp;#34;&lt;/span&gt;: (&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)})

cc1_mean &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(cc1)
cc2_mean &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(cc2)

sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;boxplot(cc1, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax_box1, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b&amp;#39;&lt;/span&gt;)
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;boxplot(cc2, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax_box2, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;)
ax_box1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(cc1_mean, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g&amp;#39;&lt;/span&gt;, linestyle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--&amp;#39;&lt;/span&gt;)
ax_box2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(cc2_mean, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;m&amp;#39;&lt;/span&gt;, linestyle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots_adjust(top&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.87&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;suptitle(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;correlation coefficient n=&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(len(cc1)), fontsize &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;)

sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(cc1, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax_dist, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rtf&amp;#39;&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b&amp;#39;&lt;/span&gt;, norm_hist&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(cc2, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax_dist, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rtm&amp;#39;&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;, norm_hist&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
ax_dist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(cc1_mean, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g&amp;#39;&lt;/span&gt;, linestyle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--&amp;#39;&lt;/span&gt;)
ax_dist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(cc2_mean, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;m&amp;#39;&lt;/span&gt;, linestyle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
ax_box1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set(xlabel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;)
ax_box2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set(xlabel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;savefig(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/home/jeonj1/proj/mi/cc_box_distplot.png&amp;#39;&lt;/span&gt;)


&lt;span style=&#34;color:#75715e&#34;&gt;# let&amp;#39;s plot box-dist plot combined&lt;/span&gt;
f, (ax_box1, ax_box2, ax_dist) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, sharex&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, gridspec_kw&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;height_ratios&amp;#34;&lt;/span&gt;: (&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)})

mi1_mean &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(mi1)
mi2_mean &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(mi2)

sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;boxplot(mi1, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax_box1, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b&amp;#39;&lt;/span&gt;)
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;boxplot(mi2, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax_box2, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;)
ax_box1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(mi1_mean, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g&amp;#39;&lt;/span&gt;, linestyle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--&amp;#39;&lt;/span&gt;)
ax_box2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(mi2_mean, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;m&amp;#39;&lt;/span&gt;, linestyle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots_adjust(top&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.87&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;suptitle(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mutual information n=&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(len(cc1)), fontsize &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;)

sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(mi1, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax_dist, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rtf&amp;#39;&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b&amp;#39;&lt;/span&gt;, norm_hist&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(mi2, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax_dist, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rtm&amp;#39;&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;, norm_hist&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
ax_dist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(mi1_mean, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g&amp;#39;&lt;/span&gt;, linestyle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--&amp;#39;&lt;/span&gt;)
ax_dist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(mi2_mean, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;m&amp;#39;&lt;/span&gt;, linestyle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
ax_box1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set(xlabel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;)
ax_box2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set(xlabel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;savefig(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/home/jeonj1/proj/mi/mi_box_distplot.png&amp;#39;&lt;/span&gt;)

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following code above will generate two joint plots that combine the box plot and distribution plot for correlation coefficient and mutual information. The first image below shows the correlation coefficient distribution (note that the max is at 1.00). The N here represents the total number of scan images that were compared.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;cc_box_distplot.png&#34; alt=&#34;CC distribution plot for rtf vs rtm&#34; title=&#34;CC distribution plot for rtf vs rtm&#34;&gt;&lt;/p&gt;
&lt;p&gt;The image below is what we&amp;rsquo;re really interested in (!The title should be changed to MI!). You can see the values range from 0.6~1.4. Also, it shows evidence that RTF version has outliers depicted in the box plot, but the outlier is moderated with the RTM method.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;mi_box_distplot.png&#34; alt=&#34;MI distribution plot for rtf vs rtm&#34; title=&#34;MI distribution plot for rtf vs rtm&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;references--useful-links&#34;&gt;References &amp;amp; Useful Links&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://people.csail.mit.edu/fisher/publications/papers/tsai99.pdf&#34;&gt;https://people.csail.mit.edu/fisher/publications/papers/tsai99.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.87.2130&amp;amp;rep=rep1&amp;amp;type=pdf&#34;&gt;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.87.2130&amp;amp;rep=rep1&amp;amp;type=pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://matthew-brett.github.io/teaching/mutual_information.html#t1-t2-scatter&#34;&gt;https://matthew-brett.github.io/teaching/mutual_information.html#t1-t2-scatter&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Universal Sentence Encoder and GloVe on Narrative Semantic Representation</title>
      <link>https://jinjeon.me/post/vectorspace/</link>
      <pubDate>Thu, 01 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://jinjeon.me/post/vectorspace/</guid>
      <description>&lt;p&gt;&lt;strong&gt;See full repo at &lt;a href=&#34;https://github.com/jeon11/use-glove-narrative.git&#34;&gt;https://github.com/jeon11/use-glove-narrative.git&lt;/a&gt;&lt;/strong&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;strong&gt;Note:&lt;/strong&gt; The results are shown in the &lt;a href=&#34;https://jinjeon.me/#posters&#34;&gt;poster&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Google&amp;rsquo;s Universal Sentence Encoder (USE)&lt;/strong&gt; provides 512-dimension vectors for each input that are pre-trained on large corpus, and can be plugged into a variety of different task models, such as sentiment analysis, classification, and etc. It is speed-efficient without losing task accuracy, and also provides embeddings not just for word level, but also for phrases, sentences, and even paragraphs. However, the more the words are given as input, the more likely each word meaning gets diluted.&lt;/p&gt;
&lt;p&gt;This notebook is based on the Semantic Similarity with TF-Hub Universal Encoder tutorial, but uses a separate input from one of the projects. We will also use &lt;strong&gt;GloVe&lt;/strong&gt; vectors to compare how the vectors and cosine similarity differ between the two models.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;First, the notebook goes over setting up locally and use one sample data to create embeddings saved out as a separate csv file using Pandas.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then assuming you have cloned the repository, we call in custom functions to quickly extract vectors of given word, phrase, sentences in USE and GloVe.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;table-of-contentsshort-cuts&#34;&gt;Table of Contents/Short-cuts:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#About-USE-Models-and-Deep-Average-Network&#34;&gt;About USE Models and Deep Average Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Installation-&amp;amp;-Setup&#34;&gt;Installation &amp;amp; Setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Path-Setup&#34;&gt;Path Setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Raw-Data-Format&#34;&gt;Raw Data Format&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Get-USE-Embeddings&#34;&gt;Get USE Embeddings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Cosine-Similarity&#34;&gt;Cosine Similarity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Cosine-Similarity-Example&#34;&gt;Cosine Similarity Examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Plotting-Similarity-Matrix&#34;&gt;Plotting Similarity Matrix&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;about-use-models-and-deep-average-network&#34;&gt;About USE Models and Deep Average Network&lt;/h3&gt;
&lt;p&gt;There are two types of models in &lt;strong&gt;USE&lt;/strong&gt;: &lt;strong&gt;Transformer&lt;/strong&gt; and &lt;strong&gt;Deep Averaging Network (DAN)&lt;/strong&gt;. We will use DAN which is a lighter version for efficiency and speed in exchange for reduced accuracy (still accurate enough).&lt;/p&gt;
&lt;p&gt;DAN first averages the input word embeddings to create a sentence embedding. It uses PTB tokenizer, which divides a sentence into a sequence of tokens based on set of rules on  how to process punctuation, articles, etc, in order to create 512 dimension embeddings. This averaged 512 vector is passed to one or more feedforward layers. Then it is multi-task-trained on unsupervised data drawn from various internet sources,  Wikipedia, Stanford Natural Language Inference corpus, web news, and forums.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Training  goals:
&lt;ul&gt;
&lt;li&gt;Uses skip-thought-like model that predicts the surrounding sentences of a given text (see below)&lt;/li&gt;
&lt;li&gt;Conversational response suggestion&lt;/li&gt;
&lt;li&gt;Classification task on supervised data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The intuition behind deep feedforward neural network is that each layer learns a more abstract representation of the input than the previous one. So its depth allows to capture subtle variations of the input with more depths. Also, each layer only involves a single matrix multiplication, allowing minimal computing time.&lt;/p&gt;
&lt;p&gt;See full USE paper: &lt;a href=&#34;https://arxiv.org/pdf/1803.11175.pdf&#34;&gt;https://arxiv.org/pdf/1803.11175.pdf&lt;/a&gt;
See full DAN paper: &lt;a href=&#34;https://people.cs.umass.edu/~miyyer/pubs/2015_acl_dan.pdf&#34;&gt;https://people.cs.umass.edu/~miyyer/pubs/2015_acl_dan.pdf&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;installation--setup&#34;&gt;Installation &amp;amp; Setup&lt;/h3&gt;
&lt;p&gt;I used Anaconda to create a TensorFlow-specific environment to customize the package versions. After installing Anaconda&amp;hellip;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Creating a new environment:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;conda create -n py3 python=3.6.8
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;
&lt;p&gt;Activate the created environment by &lt;code&gt;conda activate py3&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Using pip, install packages for pandas, numpy, seaborn, tensorflow, tensorflow_hub. ie. &lt;code&gt;pip install pckge-name&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then, let&amp;rsquo;s make sure to set the packages to exact version:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;pip install --upgrade tensorflow=1.15.0
pip install --upgrade tensorflow-hub=0.7.0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once the steps are done, we should be able to run the codes locally.&lt;/p&gt;
&lt;hr&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; absl &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; logging
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_hub &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; hub
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; glob &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; glob
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; re
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; sns
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;
due to some depecrated methods and changes made with the tf version upgrade from tf1.X to tf2.0, here we use a specific set of Python and tf versions. You can check via &lt;code&gt;pip freeze&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tested on python == 3.6.8 | tensorflow == 1.15.0 | tensorflow_hub == 0.7.0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Or you can check the version in Python via:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; sys
print(sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;version_info)  &lt;span style=&#34;color:#75715e&#34;&gt;# sys.version_info(major=3, minor=6, micro=8, releaselevel=&amp;#39;final&amp;#39;)&lt;/span&gt;
print(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__version__)    &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#39;1.15.0&amp;#39;&lt;/span&gt;
print(hub&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__version__)   &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#39;0.7.0&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# script variables&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# for lite/DAN version:&lt;/span&gt;
module_url &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://tfhub.dev/google/universal-sentence-encoder/2&amp;#34;&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# for heavy/Transformer version:&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# module_url = &amp;#34;https://tfhub.dev/google/universal-sentence-encoder-large/3&amp;#34;&lt;/span&gt;

baseDir &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;use-glove-narrative&amp;#39;&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# repository/base folder name&lt;/span&gt;
embedding_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;512&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# base 512-dimension embedding&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h3 id=&#34;path-setup&#34;&gt;Path Setup&lt;/h3&gt;
&lt;p&gt;Assuming that you git cloned the project (which is for demo purposes) to your local directory, we set the path so the code knows where to look for certain data files using the &lt;code&gt;baseDir&lt;/code&gt; specified above. We will mainly just work within the cloned folder.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;pwd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;getcwd()
&lt;span style=&#34;color:#75715e&#34;&gt;# recursively find absolute path&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;basename(pwd) &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; baseDir:
    os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;chdir(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;..&amp;#39;&lt;/span&gt;)
    pwd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;getcwd()
baseDir &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pwd
dataDir &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; baseDir &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/data&amp;#39;&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# recursively find all csv files. We will work with one file here&lt;/span&gt;
all_csvs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [y &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;walk(dataDir) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; y &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; glob(os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join(x[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;*.csv&amp;#39;&lt;/span&gt;))]
all_csvs&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sort()
all_csvs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; all_csvs[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]  &lt;span style=&#34;color:#75715e&#34;&gt;# we will just use one sample data&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;raw-data-format&#34;&gt;Raw Data Format&lt;/h3&gt;
&lt;p&gt;To briefly show the data, the data is comprised of numerous idea units, or phrases of words with unique meanings. Here, we are only interested in the &amp;lsquo;text&amp;rsquo; column and &amp;lsquo;index&amp;rsquo; column. We will call in the text of the entire story to create embeddings for each idea unit. Below the example print out, we will loop over each story to create embeddings. Since we will use one story this time, it shouldn&amp;rsquo;t take that long.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# an example print of data format&lt;/span&gt;
datafile &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(all_csvs)
datafile&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;!-- raw HTML omitted --&gt;
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;hr&gt;
&lt;h2 id=&#34;get-use-embeddings&#34;&gt;Get USE Embeddings&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# let&amp;#39;s read in the data file&lt;/span&gt;
textfile &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(all_csvs)
&lt;span style=&#34;color:#75715e&#34;&gt;# get the title of the narrative story, cutting out the .csv extension&lt;/span&gt;
title &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;basename(all_csvs)[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;]


&lt;span style=&#34;color:#75715e&#34;&gt;# create df to save out at the end&lt;/span&gt;
vector_df_columns &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;paragraph&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;index&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;size&amp;#39;&lt;/span&gt;]
&lt;span style=&#34;color:#75715e&#34;&gt;# create column for each dimension (out of 512)&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, embedding_size &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
    vector_df_columns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dim&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(i))
vector_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(columns&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;vector_df_columns)


&lt;span style=&#34;color:#75715e&#34;&gt;# import the Universal Sentence Encoder&amp;#39;s TF Hub module&lt;/span&gt;
embed &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; hub&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Module(module_url)  &lt;span style=&#34;color:#75715e&#34;&gt;# hub.load(module_url) for tf==2.0.0&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# we call in the text column from data file&lt;/span&gt;
messages &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; t &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(textfile)):
    messages&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(textfile&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iloc[t][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;])

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Reduce logging output.&lt;/span&gt;
logging&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_verbosity(logging&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ERROR)

&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;v1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Session() &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; session:
    session&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run([tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;v1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;global_variables_initializer(), tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;v1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tables_initializer()])
    message_embeddings &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; session&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run(embed(messages))

&lt;span style=&#34;color:#75715e&#34;&gt;# make sure all units are there/sanity check&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;assert&lt;/span&gt; len(message_embeddings) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; len(textfile) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; len(messages)

&lt;span style=&#34;color:#75715e&#34;&gt;# loop over each vector value to corresponding text&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; e &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(message_embeddings)):
    vector_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;at[e, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;paragraph&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; textfile&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iloc[e][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;paragraph&amp;#39;&lt;/span&gt;]
    vector_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;at[e, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;index&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; textfile&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iloc[e][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;index&amp;#39;&lt;/span&gt;]
    vector_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;at[e, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; messages[e]
    vector_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;at[e, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;size&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; len(message_embeddings[e])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; dim &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(message_embeddings[e])):
        vector_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;at[e, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dim&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;str(dim&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; message_embeddings[e][dim]

&lt;span style=&#34;color:#75715e&#34;&gt;# display sample format&lt;/span&gt;
vector_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;INFO:tensorflow:Saver not created because there are no variables in the graph to restore


INFO:tensorflow:Saver not created because there are no variables in the graph to restore
&lt;/code&gt;&lt;/pre&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;print(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape(vector_df))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(0, 516)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The sample data shows each idea unit/text converted to 512 dimension vectors. &lt;code&gt;np.shape(vector_df)&lt;/code&gt; will return a 41 total idea units/phrases to 516 columns (512 dimensions + custom columns (paragraph info, index, text, and size)). We then use these vectors to explore semantic similarity between text and phrases.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# run the code below to save out as csv file&lt;/span&gt;
vector_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reindex(columns&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;vector_df_columns)
vector_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_csv(title &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;_vectors.csv&amp;#39;&lt;/span&gt;, index&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;cosine-similarity&#34;&gt;Cosine Similarity&lt;/h2&gt;
&lt;p&gt;As a brief description, &lt;strong&gt;cosine similarity&lt;/strong&gt; is basically the measure of cosine angle between the two vectors. Since we have USE and GloVe vectors that represent words into multidimensional vectors, we can apply these vector values to calculate how similar the two words are.&lt;/p&gt;
&lt;p&gt;It can be easily calculated in Python with its useful packages:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;cos_sim &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; numpy&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(vector1, vector2)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(numpy&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(vector1) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; numpy&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(vector2))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Assuming we established some basic understanding, let&amp;rsquo;s call in the functions I made so that we can easily get USE and GloVe vectors at multiple word level.&lt;/p&gt;
&lt;p&gt;I will highlight some of the functions below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; get_glove_use &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;
help(glove_vec)
help(use_vec)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Help on function glove_vec in module get_glove_use:

glove_vec(item1, item2)
    get vectors for given two words and calculate cosine similarity

    Parameters
    ----------
    item1 : str
        string in glove word pool vector to compare
    item2 : str
        string in glove word pool vector to compare

    Returns
    -------
    item1_vector : array
        item1 GloVe vector
    item2_vector : array
        item2 GloVe vector
    cos_sim : float
        cosine similarity of item1 and item2 vectors

Help on function use_vec in module get_glove_use:

use_vec(item1, item2)
    get USE vectors and cosine similairty of the two items

    Parameters
    ----------
    item1 : str, list
        any word to compare, put in string for more than one word
    item2 : str, list
        any word to compare, put in string for more than one word

    Returns
    -------
    item1_vector : array
        item1 USE vector
    item2_vector : array
        item2 USE vector
    cos_sim : float
        cosine similarity of item1 and item2 vectors
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;cosine-similarity-example&#34;&gt;Cosine Similarity Example&lt;/h3&gt;
&lt;p&gt;Using the two functions above, and another function compare_word_vec (which basically uses the two functions), we can easily obtain cosine similarity of two words.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# using the two functions above, we can get&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# GloVe and USE vectors and cosine similarity of two input words&lt;/span&gt;
os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;chdir(gloveDir)
_, _, glove_sim &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; glove_vec(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;fish&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bear&amp;#39;&lt;/span&gt;)
_, _, use_sim &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; use_vec(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;fish&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bear&amp;#39;&lt;/span&gt;)
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;use cos: &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(use_sim))
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;glove cos: &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(glove_sim))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;INFO:tensorflow:Saver not created because there are no variables in the graph to restore


INFO:tensorflow:Saver not created because there are no variables in the graph to restore


0.11964830574261577
0.5305143
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# the two functions glove_vex and use_vec are use in compare_word_vec&lt;/span&gt;
compare_word_vec(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;man&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;fish&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;INFO:tensorflow:Saver not created because there are no variables in the graph to restore


INFO:tensorflow:Saver not created because there are no variables in the graph to restore


use cos: 0.49838725
glove cos: 0.18601566881803455
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; From the example above, USE and GloVe similarly identy &lt;em&gt;fish&lt;/em&gt; to be somewhat equally similar to &lt;em&gt;bear&lt;/em&gt; and &lt;em&gt;man&lt;/em&gt; (but just in different scale/degree).&lt;/p&gt;
&lt;p&gt;Now let&amp;rsquo;s try comparing at multiple words or phrase level. We will use new functions and give in new inputs as strings.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sentence1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;old&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;man&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;caught&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;fish&amp;#39;&lt;/span&gt;]
sentence2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bear&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;hunted&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;trout&amp;#39;&lt;/span&gt;]
sentence3 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bear&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;eat&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;six&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;fish&amp;#39;&lt;/span&gt;]

print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;old man caught fish &amp;amp; bear hunted trout:&amp;#39;&lt;/span&gt;)
phrase_vec(sentence1, sentence2)

print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;old man caught fish &amp;amp; bear eat six fish:&amp;#39;&lt;/span&gt;)
phrase_vec(sentence1, sentence3)

print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bear hunted trout &amp;amp; bear eat six fish:&amp;#39;&lt;/span&gt;)
phrase_vec(sentence2, sentence3)

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;old man caught fish &amp;amp; bear hunted trout:
INFO:tensorflow:Saver not created because there are no variables in the graph to restore


INFO:tensorflow:Saver not created because there are no variables in the graph to restore


glove sim: 0.36609688461789297
USE sim: 0.50494814
old man caught fish &amp;amp; bear eat six fish:
INFO:tensorflow:Saver not created because there are no variables in the graph to restore


INFO:tensorflow:Saver not created because there are no variables in the graph to restore


glove sim: 0.6818474640845398
USE sim: 0.5896743
bear hunted trout &amp;amp; bear eat six fish:
INFO:tensorflow:Saver not created because there are no variables in the graph to restore


INFO:tensorflow:Saver not created because there are no variables in the graph to restore


glove sim: 0.6082457470353315
USE sim: 0.72352856
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; From the example above, we can see that USE and GloVe capture somewhat differently. We can see that &lt;em&gt;bear hunted trout&lt;/em&gt; and &lt;em&gt;bear eat six fish&lt;/em&gt; are the most similar to each other, whereas &lt;em&gt;old man caught fish&lt;/em&gt; is also similar to the context of bear eating six fish.&lt;/p&gt;
&lt;p&gt;More detailed analysis is required, but the example above shows great possibilities to exploring semantics.&lt;/p&gt;
&lt;h3 id=&#34;plotting-similarity-matrix&#34;&gt;Plotting Similarity Matrix&lt;/h3&gt;
&lt;p&gt;Now that we can compare similarity of words and sentences, we can plot a simple pairwise matrix, which basically compares how similar each word is to another in the given list. Fortunately, we already have a plot for doing it (using Seaborn).&lt;/p&gt;
&lt;p&gt;I will only use few words as demonstration, since it&amp;rsquo;s been slowing up my computer so much!&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plot_sim_matrix([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;man&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bear&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;fish&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;trout&amp;#39;&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;INFO:tensorflow:Saver not created because there are no variables in the graph to restore


INFO:tensorflow:Saver not created because there are no variables in the graph to restore
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./use_glove_cosine_similarity_25_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;ending-note&#34;&gt;Ending Note&lt;/h2&gt;
&lt;p&gt;In the example above, we only used simple noun words. The stronger blue color, the more similar the two words are. Thus, the diagonal strip is deep blue (similarity of same two words is 1). You can see &lt;em&gt;fish&lt;/em&gt; and &lt;em&gt;trout&lt;/em&gt; are more similar to each other, than is &lt;em&gt;man&lt;/em&gt; to &lt;em&gt;trout&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Keep in mind that you can feed in more words and sentences to create and visualize a larger matrix.&lt;/p&gt;
&lt;p&gt;We looked at setting up USE locally, and creating embeddings from USE. The cloned project also has sample version of GloVe vectors. We use the vectors from the two models to extract vectors and compare similarity of two texts.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>EEG/Signal Processing--Advanced Part 2</title>
      <link>https://jinjeon.me/post/eeg-advanced/</link>
      <pubDate>Wed, 02 May 2018 00:00:00 +0000</pubDate>
      <guid>https://jinjeon.me/post/eeg-advanced/</guid>
      <description>&lt;h3 id=&#34;note&#34;&gt;Note:&lt;/h3&gt;
&lt;p&gt;This post is a ported version of Jupyter Notebook from my mne-eeg project: &lt;a href=&#34;https://github.com/jeon11/mne-egi/blob/master/walkthrough_advanced.ipynb/walkthrough_basics.ipynb&#34;&gt;https://github.com/jeon11/mne-egi/blob/master/walkthrough_advanced.ipynb/walkthrough_basics.ipynb&lt;/a&gt;
&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h2 id=&#34;advanced-processing&#34;&gt;Advanced Processing&lt;/h2&gt;
&lt;p&gt;In the previous walkthrough notebook, we got to manually inspect raw instance and do some cleaning based on annotations and creating evoked responses from time-locked events.&lt;/p&gt;
&lt;p&gt;In this section, we run independent component analysis (ICA) on the epochs we had from the last notebook. We look in ICs to identify potentially bad components with eye related artifcats. Then, we implement autoreject (&lt;a href=&#34;http://autoreject.github.io&#34;&gt;http://autoreject.github.io&lt;/a&gt;) which automatically attempts to find bad channels and interpolate those based on nearby channels. At the end, we plot the ERPs by channels that we are interested in looking and make comparison.&lt;/p&gt;
&lt;p&gt;Note that the plots below will be using &lt;code&gt;print&lt;/code&gt; statements for demonstration purposes.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; mne
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; matplotlib &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pyplot &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Tkinter
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; autoreject &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; AutoReject
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; autoreject &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; get_rejection_threshold
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; mne.preprocessing &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ICA
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;loading-epochs&#34;&gt;Loading epochs&lt;/h3&gt;
&lt;p&gt;We imported all the necessary dependencies. Now we load the saved epochs from last notebook.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;epochs_tlstS &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mne&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_epochs(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/data/epochs_tlsts-epo.fif&amp;#39;&lt;/span&gt;, preload&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
print(epochs_tlstS)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;EpochsFIF  |   388 events (all good), -0.25 - 0.8 sec, baseline [-0.25, 0], ~72.8 MB, data loaded, with metadata,
 u&#39;lstS&#39;: 388&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;running-independent-component-analysis-ica&#34;&gt;Running Independent Component Analysis (ICA)&lt;/h2&gt;
&lt;p&gt;ICA is a signal processing method to decompose signals into independent sources from a mixed signal. A representative example is the cocktail party effect, which is a phenomenon in which you are able to concentrate on the voice of the speaker  you are conversing with regardless of the various background noise in a party. Using ICA helps seperate the different sources of mixed sound, under the assumption that the sound components are linear. This method works for EEG signal preprocessing because we assume that each electrode is independent from the others. To think of it easily, I consider ICA as decomposing the data into multiple layers, and by excluding bad ICs, we filter the data.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# the function calculates optimal reject threshold for ICA&lt;/span&gt;
reject &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_rejection_threshold(epochs_tlstS)
print(reject)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Estimating rejection dictionary for eeg
Estimating rejection dictionary for eog
{&#39;eeg&#39;: 0.0007759871430524497, &#39;eog&#39;: 5.903189072009943e-05}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;low-frequency-slow-drifts&#34;&gt;Low-frequency slow drifts&lt;/h3&gt;
&lt;p&gt;Because ICA is sensitive to low-frequency slow drifts, it is recommended that 1Hz highpass filter is applied. Since this was already done to our raw instance in the previous notebook, it can be skipped. You can double check as below, or apply the highpass filter if you haven&amp;rsquo;t already.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# double check highpass filter&lt;/span&gt;
print(epochs_tlstS&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;highpass&amp;#39;&lt;/span&gt;])

&lt;span style=&#34;color:#75715e&#34;&gt;# epochs_tlstS.info[&amp;#39;highpass&amp;#39;] = 1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;1.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;fit-ica&#34;&gt;Fit ICA&lt;/h3&gt;
&lt;p&gt;Now we will run ICA on our epoch data. For simplicity and time sake, we will limit the number of components to 20 with fastICA method, which is the generally used one. The number of ICs can be created up to as many electrodes (in this case 128 - bad channels). In &lt;code&gt;ica1.fit&lt;/code&gt;, we use the recommended reject threshold from Autoreject.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;ica &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ICA(n_components&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;, max_pca_components&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;, n_pca_components&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;, noise_cov&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;,
           random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;, method&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;fastica&amp;#39;&lt;/span&gt;, fit_params&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;, max_iter&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;200&lt;/span&gt;, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;)
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;fitting ica...&amp;#39;&lt;/span&gt;)
ica&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(epochs_tlstS, reject&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;reject)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;fitting ica...


/Users/Jin/Library/Python/2.7/lib/python/site-packages/scipy/linalg/basic.py:1321: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to &#39;gelss&#39; driver.
  x, resids, rank, s = lstsq(a, b, cond=cond, check_finite=False)





&amp;lt;ICA  |  epochs decomposition, fit (fastica): 81868 samples, 20 components, channels used: &amp;quot;eeg&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;artifact-detection-using-ica-correlation&#34;&gt;Artifact detection using ICA correlation&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;plot_sources&lt;/code&gt; can show the signals of each ICs. We can manually inspect for ICs with noise, or identify bad ICs that correlates with oscillations from eye-related channels. We use the builtin &lt;code&gt;find_bads_eog&lt;/code&gt; from ICA class.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;plot_scores&lt;/code&gt; will show the correlation values for each component, and mark the ones that are potentially bad with red. Note that because we only specified 20 components, the decomposition is rather compressed.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;eog_inds, scores &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ica&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;find_bads_eog(epochs_tlstS)
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;suggested eog component: &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(eog_inds))
print(ica&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_scores(scores, exclude&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;eog_inds, labels&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;eog&amp;#39;&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;suggested eog component: [3]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./walkthrough_advanced_11_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Figure(460.8x194.4)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;find_bads_eog&lt;/code&gt; suggested that component &amp;lsquo;3&amp;rsquo; is bad IC related to eye-related artifact. We can plot that specific component to inspect manually.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;print(ica&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_properties(epochs_tlstS, picks&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;eog_inds, psd_args&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;fmax&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;35.&lt;/span&gt;}, image_args&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sigma&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt;}))
ica&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exclude &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; eog_inds
print(ica&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exclude)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;/Users/Jin/Library/Python/2.7/lib/python/site-packages/mne/transforms.py:689: RuntimeWarning: invalid value encountered in divide
  out[:, 2] = np.arccos(cart[:, 2] / out[:, 0])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./walkthrough_advanced_13_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&amp;lt;Figure size 504x432 with 5 Axes&amp;gt;]
[3]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Usually, eye blinks are characterized as having significantly polar activities between the frontal and the posterior regions with high activity in the frontal region (ie. eyes). Also, activities shown in the frontal region, especially near the eye area, would not be helpful in our analysis. Eye movements are characterized as having significantly split activities between left and right. Component above does seem containing eye blinks, we mark that component bad by &lt;code&gt;ica.exclude&lt;/code&gt; and we can see that component has been added.&lt;/p&gt;
&lt;p&gt;We can also manually inspect for other components using &lt;code&gt;plot_components&lt;/code&gt; besides the ones that the builtin method suggested. You can see that the component speficied above being grayed out as a bad IC. The plot prioritizes showing ICs with large activations and polarity, which means that most of the bad ICs could be found in the early ICs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;print(ica&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_components(inst&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;epochs_tlstS))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./walkthrough_advanced_15_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&amp;lt;Figure size 540x504 with 20 Axes&amp;gt;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When running the code on &lt;code&gt;ipython&lt;/code&gt; as suggested in the previous notebook, the plot is actually interactive. By clicking on the component, it shows the component properties. Clicking on the name of the component will gray out the name and be marked as bad IC. Here, it seems components 2, 14, and 18 have high activation in the eye regions, which could be identified as components with eye blinks. Also, componnent 5 has activation in the frontal region, and has polar activities between left and right, which could potentially be eye movements. Because the plot above is not interactive, we will specify which ICs to exclude as a line of code.&lt;/p&gt;
&lt;p&gt;Since we&amp;rsquo;ve identified the bad ICs, we can apply it to our epochs_tlstS, and proceed to autoreject.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;ica&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exclude &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;18&lt;/span&gt;]
print(ica&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exclude)
ica&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply(epochs_tlstS)
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;number of ICs dropped: &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(len(ica&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exclude)))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[3, 0, 2, 5, 14, 18]
number of ICs dropped: 6
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;autoreject&#34;&gt;Autoreject&lt;/h2&gt;
&lt;p&gt;Now that we have bad ICs identified, we try implementing autoreject for cleaning. Note that the step below may take some time as it tries find bad channels and fix them.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;ar &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AutoReject()
epochs_clean &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ar&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_transform(epochs_tlstS)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Running autoreject on ch_type=eeg
[........................................] 100.00% Creating augmented epochs \ Computing thresholds ...
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.5s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    7.3s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.5s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   13.2s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   16.4s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   19.5s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   21.7s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   24.6s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   27.5s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   30.3s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:   33.4s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:   35.4s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   36.8s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:   38.4s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:   40.2s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:   42.2s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:   44.8s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   47.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:   48.7s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:   50.1s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:   51.6s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   53.1s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   54.8s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:   56.4s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   57.9s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:   59.8s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  1.0min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.1min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  1.1min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  1.1min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  1.1min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:  1.2min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  1.2min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  1.2min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:  1.2min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:  1.3min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  1.3min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  1.3min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed:  1.4min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:  1.4min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:  1.4min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed:  1.4min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.5min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed:  1.5min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed:  1.5min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:  1.6min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:  1.6min remaining:    0.0s
[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.6min remaining:    0.0s
[Parallel(n_jobs=1)]: Done 115 out of 115 | elapsed:  3.8min finished
[........................................] 100.00% n_interp \   chs |   



Estimated consensus=0.30 and n_interpolate=4
[........................................] 100.00% Repairing epochs |   
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above created a new epochs called &lt;code&gt;epochs_clean&lt;/code&gt;. We can compare how the epochs are cleaned by comparing the two plots. For demonstration, we only plot the &lt;code&gt;epochs_clean&lt;/code&gt;. The plot shows individual epochs with green line being 0 (the onset of the word in the experiment). In the interactive plot mode, you can scroll vertically to see different channels and horizontally to search through epochs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;print(epochs_clean&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./walkthrough_advanced_21_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Figure(869.6x536.8)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;creating-evoked-response-from-epochs_clean&#34;&gt;Creating evoked response from epochs_clean&lt;/h2&gt;
&lt;p&gt;Now that we have a new, ideally cleaner epochs, we create evoked response for each condition. Currently, &lt;code&gt;epochs_clean&lt;/code&gt; contains all four conditions with approximately 100 epochs for each (less than 400 now because epochs been rejected). Note that the y-axis microvolt scale has been refined compared to our previous notebook.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# now let&amp;#39;s create a new evoked responses (ie. the autoreject evoked)&lt;/span&gt;
arevoked_tlst_c1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; epochs_clean[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;label==&amp;#39;lstS&amp;#39; and cond==&amp;#39;1&amp;#39;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;average()
arevoked_tlst_c2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; epochs_clean[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;label==&amp;#39;lstS&amp;#39; and cond==&amp;#39;2&amp;#39;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;average()
arevoked_tlst_c3 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; epochs_clean[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;label==&amp;#39;lstS&amp;#39; and cond==&amp;#39;3&amp;#39;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;average()
arevoked_tlst_c4 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; epochs_clean[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;label==&amp;#39;lstS&amp;#39; and cond==&amp;#39;4&amp;#39;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;average()

&lt;span style=&#34;color:#75715e&#34;&gt;# let&amp;#39;s see a sample evoked response&lt;/span&gt;
print(arevoked_tlst_c1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_joint(times&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;peaks&amp;#39;&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./walkthrough_advanced_23_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Figure(576x302.4)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;plotting-erp-comparison&#34;&gt;Plotting ERP comparison&lt;/h2&gt;
&lt;p&gt;Now that we have evoked response for each condition, we can look into specific channels of interest to see how the signals differ by conditions. For the selection list, we will only specify channel E92 as it will create 4 graphs for each channel.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# we specify which channels to look at&lt;/span&gt;
selection &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E92&amp;#39;&lt;/span&gt;]  &lt;span style=&#34;color:#75715e&#34;&gt;# [&amp;#39;EB&amp;#39;,&amp;#39;E11&amp;#39;,&amp;#39;E24&amp;#39;,&amp;#39;E124&amp;#39;,&amp;#39;E36&amp;#39;,&amp;#39;E104&amp;#39;,&amp;#39;E52&amp;#39;,&amp;#39;E62&amp;#39;,&amp;#39;E92&amp;#39;]&lt;/span&gt;
picks_select &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mne&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pick_types(epochs_clean&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info, meg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;, eeg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, eog&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, stim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;,
                              exclude&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bads&amp;#39;&lt;/span&gt;, selection&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;selection)

&lt;span style=&#34;color:#75715e&#34;&gt;# create dictionary for each condition&lt;/span&gt;
evoked_dict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;highcosval&amp;#39;&lt;/span&gt;: arevoked_tlst_c1,
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lowcosval&amp;#39;&lt;/span&gt;: arevoked_tlst_c2,
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;highcosinval&amp;#39;&lt;/span&gt;: arevoked_tlst_c3,
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lowcosinval&amp;#39;&lt;/span&gt;: arevoked_tlst_c4}

picks_select &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mne&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pick_types(arevoked_tlst_c1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info, meg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;, eeg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, eog&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, stim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;,
                              exclude&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bads&amp;#39;&lt;/span&gt;, selection&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;selection)


&lt;span style=&#34;color:#75715e&#34;&gt;# this will plot each selected channel with comparison of two conditions&lt;/span&gt;
title &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;_vs_&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;_E&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;.png&amp;#39;&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(picks_select)):
    fig1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mne&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;viz&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_compare_evokeds({&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;highcos/val&amp;#39;&lt;/span&gt;:evoked_dict[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;highcosval&amp;#39;&lt;/span&gt;],
                                         &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lowcos/val&amp;#39;&lt;/span&gt;:evoked_dict[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lowcosval&amp;#39;&lt;/span&gt;]}, picks&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;picks_select[i])
    fig2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mne&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;viz&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_compare_evokeds({&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;highcos/inval&amp;#39;&lt;/span&gt;:evoked_dict[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;highcosinval&amp;#39;&lt;/span&gt;],
                                         &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lowcos/inval&amp;#39;&lt;/span&gt;:evoked_dict[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lowcosinval&amp;#39;&lt;/span&gt;]}, picks&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;picks_select[i])
    fig3 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mne&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;viz&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_compare_evokeds({&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;highcos/val&amp;#39;&lt;/span&gt;:evoked_dict[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;highcosval&amp;#39;&lt;/span&gt;],
                                         &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;highcos/inval&amp;#39;&lt;/span&gt;:evoked_dict[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;highcosinval&amp;#39;&lt;/span&gt;]},picks&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;picks_select[i])
    fig4 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mne&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;viz&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_compare_evokeds({&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lowcos/val&amp;#39;&lt;/span&gt;:evoked_dict[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lowcosval&amp;#39;&lt;/span&gt;],
                                         &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lowcos/inval&amp;#39;&lt;/span&gt;:evoked_dict[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lowcosinval&amp;#39;&lt;/span&gt;]}, picks&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;picks_select[i])

    &lt;span style=&#34;color:#75715e&#34;&gt;# save figs&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# fig1.savefig(title % (evoked_dict.keys()[0], evoked_dict.keys()[1], i))&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# fig2.savefig(title % (evoked_dict.keys()[2], evoked_dict.keys()[3], i))&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# fig3.savefig(title % (evoked_dict.keys()[0], evoked_dict.keys()[2], i))&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# fig4.savefig(title % (evoked_dict.keys()[1], evoked_dict.keys()[3], i))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./walkthrough_advanced_25_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./walkthrough_advanced_25_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./walkthrough_advanced_25_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./walkthrough_advanced_25_3.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# this will plot just the evoked responses per conditions with all channels&lt;/span&gt;
fig5 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; arevoked_tlst_c1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(titles&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cond1: high cos/val&amp;#39;&lt;/span&gt;)
fig6 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; arevoked_tlst_c2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(titles&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cond2: low cos/val&amp;#39;&lt;/span&gt;)
fig7 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; arevoked_tlst_c3&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(titles&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cond3: high cos/inval&amp;#39;&lt;/span&gt;)
fig8 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; arevoked_tlst_c4&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(titles&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cond4: low cos/inval&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# save figs&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# fig5.savefig(&amp;#39;c1all.png&amp;#39;)&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# fig6.savefig(&amp;#39;c2all.png&amp;#39;)&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# fig7.savefig(&amp;#39;c3all.png&amp;#39;)&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# fig8.savefig(&amp;#39;c4all.png&amp;#39;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./walkthrough_advanced_26_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./walkthrough_advanced_26_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./walkthrough_advanced_26_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./walkthrough_advanced_26_3.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;sources-and-useful-links&#34;&gt;Sources and useful links&lt;/h2&gt;
&lt;p&gt;EEGLab ICA guide: &lt;a href=&#34;https://sccn.ucsd.edu/wiki/Chapter_09:_Decomposing_Data_Using_ICA&#34;&gt;https://sccn.ucsd.edu/wiki/Chapter_09:_Decomposing_Data_Using_ICA&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;MNE ICA class: &lt;a href=&#34;https://martinos.org/mne/stable/generated/mne.preprocessing.ICA.html&#34;&gt;https://martinos.org/mne/stable/generated/mne.preprocessing.ICA.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;autoreject: &lt;a href=&#34;http://autoreject.github.io/auto_examples/plot_auto_repair.html#sphx-glr-auto-examples-plot-auto-repair-py&#34;&gt;http://autoreject.github.io/auto_examples/plot_auto_repair.html#sphx-glr-auto-examples-plot-auto-repair-py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Clemens Brunner&amp;rsquo;s great guide on ICA: &lt;a href=&#34;https://cbrnr.github.io/2018/01/29/removing-eog-ica/&#34;&gt;https://cbrnr.github.io/2018/01/29/removing-eog-ica/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Clemens Brunner&amp;rsquo;s great guide on EOG detection using linear regression: &lt;a href=&#34;https://cbrnr.github.io/2017/10/20/removing-eog-regression/&#34;&gt;https://cbrnr.github.io/2017/10/20/removing-eog-regression/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;MNE stats: &lt;a href=&#34;https://martinos.org/mne/stable/auto_tutorials/plot_stats_cluster_erp.html#sphx-glr-auto-tutorials-plot-stats-cluster-erp-py&#34;&gt;https://martinos.org/mne/stable/auto_tutorials/plot_stats_cluster_erp.html#sphx-glr-auto-tutorials-plot-stats-cluster-erp-py&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>EEG/Signal Processing--Basics Part 1</title>
      <link>https://jinjeon.me/post/eeg-basics/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      <guid>https://jinjeon.me/post/eeg-basics/</guid>
      <description>&lt;h3 id=&#34;note&#34;&gt;Note:&lt;/h3&gt;
&lt;p&gt;This post is a ported version of Jupyter Notebook from my mne-eeg project: &lt;a href=&#34;https://github.com/jeon11/mne-egi/blob/master/walkthrough_basics.ipynb&#34;&gt;https://github.com/jeon11/mne-egi/blob/master/walkthrough_basics.ipynb&lt;/a&gt;
&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This script runs through sample experiment data from manually reading in raw file to preprocessing through applying filters, eye blink detection using peak finding techniques. Then we create epochs and plot evoked responses.&lt;/p&gt;
&lt;p&gt;In the advanced walkthrough: &lt;a href=&#34;https://github.com/jeon11/mne-egi/blob/master/walkthrough_advanced.ipynb&#34;&gt;walkthrough_advanced.ipynb&lt;/a&gt;, we implement independent component analysis (ICA) and autoreject, which is an automated tool for fixing data, to see how the epochs are improved and compare the evoked responses by conditions.&lt;/p&gt;
&lt;p&gt;The script requires at least two files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the raw data &lt;a href=&#34;https://drive.google.com/file/d/1W2UFu_6H4HzFF2DALAxfmr0BNSj7pEok/view?usp=sharing&#34;&gt;(download from Google Drive ~500MB)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;exported event text log from NetStation software&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;running-the-script-in-command-line&#34;&gt;Running the script in command line&lt;/h3&gt;
&lt;p&gt;When running the Python script from command line, MNE recommends using ipython via:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ipython —-pylab osx -i mne-egi-walkthrough.py
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For Windows, instead of &lt;code&gt;osx&lt;/code&gt;, you would be specifying &lt;code&gt;qt&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;importing&#34;&gt;Importing&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s begin by importing all the necessary modules. Make sure you have all the required dependencies setup.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; mne
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; matplotlib &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pyplot &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; mne.preprocessing &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; eog
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; mne.preprocessing &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; create_eog_epochs
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; mne.preprocessing.peak_finder &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; peak_finder
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Tkinter
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; extract_nslog_event
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;setting-basic-variables&#34;&gt;Setting basic variables&lt;/h3&gt;
&lt;p&gt;Before we begin any preprocessing, we create variables here to specify what we want to look for. The whole script basically requires two main files.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;raw_fname: The raw instance of eeg data file in .raw format&lt;/li&gt;
&lt;li&gt;ns_eventlog: Netstation&amp;rsquo;s event exports in text&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The &lt;code&gt;selection&lt;/code&gt; variable is later used to specify which channels to plot and compare. Note, the first item in the &lt;code&gt;selection&lt;/code&gt; list, &lt;code&gt;EB&lt;/code&gt; channel is a virtual channel created from bipolar referene.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# specify sample subject data directory&lt;/span&gt;
raw_fname   &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/Users/Jin/Documents/MATLAB/research/mne-egi/data/sfv_eeg_011ts.raw&amp;#39;&lt;/span&gt;
ns_eventlog &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/Users/Jin/Documents/MATLAB/research/mne-egi/data/sfv_eeg_011ts_nsevent&amp;#39;&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# specify sub-sample of channels to look in detail&lt;/span&gt;
selection &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;EB&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E11&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E24&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E124&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E36&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E104&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E52&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E62&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E92&amp;#39;&lt;/span&gt;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;reading-in-raw-file&#34;&gt;Reading in raw file&lt;/h3&gt;
&lt;p&gt;Raw eeg data can be read in with a simple line below. You can specify montage kind in strings. See &lt;a href=&#34;https://martinos.org/mne/dev/generated/mne.channels.read_montage.html&#34;&gt;https://martinos.org/mne/dev/generated/mne.channels.read_montage.html&lt;/a&gt; for available montages. We set &lt;code&gt;preload=True&lt;/code&gt; because some of the preprocessing functions require raw file to be preloaded.&lt;/p&gt;
&lt;p&gt;Once the raw file is loaded, typing &lt;code&gt;raw&lt;/code&gt; and &lt;code&gt;raw.info&lt;/code&gt; will show details about the raw instance.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;reading raw file...&amp;#39;&lt;/span&gt;)
raw &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mne&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;io&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_raw_egi(raw_fname, montage&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;GSN-HydroCel-128&amp;#39;&lt;/span&gt;, preload&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Done!&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;reading raw file...


&amp;lt;ipython-input-3-8bc42ae4bead&amp;gt;:2: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: [&#39;E129&#39;]. Their position has been left untouched.
  raw = mne.io.read_raw_egi(raw_fname, montage=&#39;GSN-HydroCel-128&#39;, preload=True)


Done!
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;print(raw)
&lt;span style=&#34;color:#75715e&#34;&gt;# see the first ten list of channel names (note by default, prefix &amp;#39;E&amp;#39; is appended)&lt;/span&gt;
print(raw&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ch_names&amp;#39;&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;])

&lt;span style=&#34;color:#75715e&#34;&gt;# see highpass &amp;amp; lowpass filter&lt;/span&gt;
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;highpass filter: &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(raw&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;highpass&amp;#39;&lt;/span&gt;]))
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lowpass filter: &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(raw&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lowpass&amp;#39;&lt;/span&gt;]))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;RawEGI  |  sfv_eeg_011ts.raw, n_channels x n_times : 136 x 989490 (4947.4 sec), ~1.00 GB, data loaded&amp;gt;
[&#39;E1&#39;, &#39;E2&#39;, &#39;E3&#39;, &#39;E4&#39;, &#39;E5&#39;, &#39;E6&#39;, &#39;E7&#39;, &#39;E8&#39;, &#39;E9&#39;, &#39;E10&#39;]
highpass filter: 0.0
lowpass filter: 100.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;applying-bandpass-filter&#34;&gt;Applying bandpass filter&lt;/h2&gt;
&lt;p&gt;Our first preprocessing step will be applying the bandpass filter of 1Hz and 30Hz. The numbers can be played around with, but this filter range will potentially remove general noise from environment and slow drifting signals. Other suggestions for highpass is 0.1; for 40 Hz lowpass.&lt;/p&gt;
&lt;p&gt;After bandpass filter is applied, type &lt;code&gt;raw.info&lt;/code&gt; to check how &lt;code&gt;raw.filter&lt;/code&gt; made changes.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# apply bandpass filter to raw file (highpass, lowpass)&lt;/span&gt;
raw&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;filter(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# see highpass &amp;amp; lowpass filter&lt;/span&gt;
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;highpass filter: &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(raw&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;highpass&amp;#39;&lt;/span&gt;]))
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lowpass filter: &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(raw&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lowpass&amp;#39;&lt;/span&gt;]))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;highpass filter: 1.0
lowpass filter: 30.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;creating-meta-dataframe&#34;&gt;Creating meta dataframe&lt;/h2&gt;
&lt;p&gt;We will deviate a little from processing raw file, and construct a dataframe that can be later used for effectively creating epochs or querying information we just need. This part uses the custom built module (also experiment specific as each experiment will have different paradigms and event tags). The &lt;code&gt;extract_nslog_event&lt;/code&gt; constructs necessary pandas dataframe from &lt;code&gt;ns_eventlog&lt;/code&gt; text file which we specified earlier in #Setting-basic-variables.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;create_df&lt;/code&gt; returns five dataframes, in which nsdata is a list from simply csv-read file that is used to create task-specific pandas dataframes. For example, &lt;code&gt;df_lst&lt;/code&gt; is the initial dataframe created that includes all practice, trials, and sentences tasks. The rest of dfs contain task specific data.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# create pandas data frames for different tasks&lt;/span&gt;
nsdata, df_lst, df_plst, df_tlst, df_slst &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; extract_nslog_event&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;create_df(ns_eventlog)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;creating data frame from ns event log...
dataframes created for subject 011
trials found: 800
sentences found: 200
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From now on, for simplicity sake, we will only examine the actual trials task part in this walkthrough. We can focus on looking at the data structure of trials task. Since the dataframe is already created specifically for trials, what we really want now is the onset (sample numbers) of when the event occured and the condition of the stimuli that was presented.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# show data frame structure of 2rd index&lt;/span&gt;
print(df_tlst&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iloc[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;code      tlst
label     lstS
onset    99867
cond         4
indx         1
Name: 2, dtype: object
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The label for trials task was either a last word start (lstS) or last word end (lstE). Since we are interested in the onset of the word, we will extract just the onsets using the custom code.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# create onset-only data frame (event tag specifications)&lt;/span&gt;
df_tlstS &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; extract_nslog_event&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;create_df_onset(df_tlst)
&lt;span style=&#34;color:#75715e&#34;&gt;# show total events of interest&lt;/span&gt;
len(df_tlstS)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;400
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;finding-impedance-check-periods-and-annotating&#34;&gt;Finding impedance check periods and annotating&lt;/h2&gt;
&lt;p&gt;Now that we have dataframes setup, we continue to clean up the raw data. Throughout the acquisition, we ran impedance checks to make sure that all electrodes were in good contact with the scalp and that good signal is being read in. During the impedance check, the waveforms peak in extreme amount and we want to make note of these periods, telling the mne functions to avoid and ignore such periods.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# find impedance onsets&lt;/span&gt;
imp_onset, imp_offset, imp_dur &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; extract_nslog_event&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;find_impedances(nsdata)

&lt;span style=&#34;color:#75715e&#34;&gt;# annotate on raw with &amp;#39;bad&amp;#39; tags (params `reject_by_annotation` will search for &amp;#39;bad&amp;#39; tags later)&lt;/span&gt;
annot_imp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mne&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Annotations(imp_onset, imp_dur, [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bad imp&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; len(imp_onset), orig_time&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;raw&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;meas_date&amp;#39;&lt;/span&gt;])
raw&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_annotations(annot_imp)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;finding impedance periods...
found 4 impedance periods!





&amp;lt;RawEGI  |  sfv_eeg_011ts.raw, n_channels x n_times : 136 x 989490 (4947.4 sec), ~1.00 GB, data loaded&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;marking-bad-channels&#34;&gt;Marking bad channels&lt;/h2&gt;
&lt;p&gt;We also want to make note of bad channels. We can manually inspect for bad channels by seeing the actual raw data.  &lt;code&gt;raw.plot&lt;/code&gt; will show the actual raw file with annotations from above marked as red segments. You can inspect for good/bad channels and manually click on bad channels to mark them bad. Once you manually inspected the channels, type &lt;code&gt;raw.info[&#39;bads&#39;]&lt;/code&gt; to see how it is updated.&lt;/p&gt;
&lt;p&gt;Note that the plot below is a static figure for example sake. Running the code in ipython will allow us to horizontally and vertically scroll through data. Clicking on a channel will mark that channel red and be considered red. You can see that we&amp;rsquo;ve ran four impedance checks throughout the session (1 task switch period, every 100th trials out fo 400).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# block=True is useful because it will wait to whatever change you make in the raw file at the plot stage&lt;/span&gt;
print(raw&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(bad_color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;red&amp;#39;&lt;/span&gt;, block&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./walkthrough_basics_19_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Figure(782.64x483.12)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you already had a list of bad channels noted during the acquisition period, you can skip the above manual inspection and simply specify the bad channels with a line of code:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;raw&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bads&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E127&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E107&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E49&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E48&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E115&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E113&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E122&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E121&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E123&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E108&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E63&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E1&amp;#39;&lt;/span&gt;]
print(raw&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bads&amp;#39;&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[&#39;E127&#39;, &#39;E107&#39;, &#39;E49&#39;, &#39;E48&#39;, &#39;E115&#39;, &#39;E113&#39;, &#39;E122&#39;, &#39;E121&#39;, &#39;E123&#39;, &#39;E108&#39;, &#39;E63&#39;, &#39;E1&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;detecting-and-rejecting-eye-blinks&#34;&gt;Detecting and rejecting eye blinks&lt;/h2&gt;
&lt;p&gt;We&amp;rsquo;ve so far applied generic/broad preprocessing steps, such as bandpass filters, marking chunks of bad segments, and marking bad channels. Now we will look at finding eye blinks in the raw and add more annotations to mark those samples bad.&lt;/p&gt;
&lt;h3 id=&#34;step-1-setting-bipolar-reference&#34;&gt;Step 1: Setting bipolar reference&lt;/h3&gt;
&lt;p&gt;Because the cap we use do not have EOG-specific channels, we use the channels that are nearest to the eyes and consider those as our virtual eye channels. Thus, such method has the risk of the eye channels actually not having just the eye-related oscillations. This is done by setting the bipolar reference, which is basically the subtraction of two opposing channels (ie. the top and bottom of each eye for eye blinks; the left and right of the eyes for eye movements).&lt;/p&gt;
&lt;p&gt;Here, we use just the right side of the eye only to detect eye blinks. From the subtraction of channel E8 and E126, a virtual channel EB is created.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# let&amp;#39;s begin eye artifact detections&lt;/span&gt;
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Starting EOG artifact detection&amp;#39;&lt;/span&gt;)
raw &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mne&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_bipolar_reference(raw, [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E8&amp;#39;&lt;/span&gt;],[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;E126&amp;#39;&lt;/span&gt;],[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;EB&amp;#39;&lt;/span&gt;])

&lt;span style=&#34;color:#75715e&#34;&gt;# specify this as the eye channel&lt;/span&gt;
raw&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_channel_types({&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;EB&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;eog&amp;#39;&lt;/span&gt;})

&lt;span style=&#34;color:#75715e&#34;&gt;# double check the changes&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# print(raw.info[&amp;#39;chs&amp;#39;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Starting EOG artifact detection
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;step-2-detecting-eye-blinks&#34;&gt;Step 2: Detecting eye blinks&lt;/h3&gt;
&lt;p&gt;Now that we have a virtual eye channel to inspect, we can try to identify any eye blinks. Because the virtual eye channel that is created from subtraction of the channels, the waveform of EB channel will be generally flat. You can inspect this by &lt;code&gt;raw.plot&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Eye blinks are generally characterized as two eye channels having sudden opposing peaks. So the methodology is to find a sudden peak within the flat EB line. We have the options of:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;finding eye blinks via mne built in function&lt;/li&gt;
&lt;li&gt;finding eye blinks via scipy peak finding method&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Both results in similar eye blink detections because the methodology of finding local peaks. We will only use the mne built in function and comment out the custom built function that uses scipy. &lt;code&gt;reject_by_annotation&lt;/code&gt; will ignore the bad segments marked as bad earlier. The threshold of 0.0001 can be played around with but it is a reasonable threshold set after having manually inspect the data. The &lt;code&gt;events_eog&lt;/code&gt; will be an array with [sample number, 0, eventlabel in number]&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;events_eog &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; eog&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;find_eog_events(raw, reject_by_annotation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, thresh&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0001&lt;/span&gt;, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# type `help(scipy_annotate_eyeblinks)` for detail&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# raw = scipy_annotate_eyeblinks(raw, &amp;#39;EB&amp;#39;, 100)&lt;/span&gt;

print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;number of eye blinks detected: &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(len(events_eog)))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;number of eye blinks detected: 1720
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;events_eog&lt;/code&gt; above will give where the eye blinks occured in samples. We will convert the sample number to seconds so we can annotate on the raw file.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# get just the sample numbers from the eog events&lt;/span&gt;
eog_sampleN &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [i[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; events_eog]
&lt;span style=&#34;color:#75715e&#34;&gt;# convert to seconds for annotation-friendly purposes&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(eog_sampleN)):
    eog_sampleN[i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; eog_sampleN[i] &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; float(&lt;span style=&#34;color:#ae81ff&#34;&gt;200&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# set annotation&lt;/span&gt;
annot_eog &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mne&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Annotations(eog_sampleN, [&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; len(eog_sampleN),
                            [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bad eye&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; len(eog_sampleN), orig_time &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; raw&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;meas_date&amp;#39;&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# add this eye blink annotation to the previous annotation by simply adding&lt;/span&gt;
new_annot &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; annot_imp &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; annot_eog
raw&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_annotations(new_annot)
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;new annotation set!&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;new annotation set!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that new annotation is set, let&amp;rsquo;s see the changes made to the raw. Again we will just have a figure printed out here. You can see the bad channels marked red (like E1), and bunch of red bars that potentially mark spikes/eye blinks. Because the Times x-axis is so zoomed out, we see all parts being red, but as we see the plot above, that is actually not true. We see that &amp;lsquo;bad eye&amp;rsquo; is annotated for any potential peaks in the &amp;lsquo;EB&amp;rsquo; channel that is newly created from bipolar reference.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# you can check that more red segments are marked on the raw file&lt;/span&gt;
print(raw&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(bad_color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;red&amp;#39;&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./walkthrough_basics_30_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Figure(782.64x483.12)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;setting-rereference&#34;&gt;Setting rereference&lt;/h2&gt;
&lt;p&gt;Now that bad channels are marked and we know which bad segments to avoid, we will set eeg reference (We want to avoid doing reference before the bad data are marked and rejected).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;setting eeg reference...&amp;#39;&lt;/span&gt;)
raw&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_eeg_reference(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;average&amp;#39;&lt;/span&gt;, projection&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;setting eeg reference...





&amp;lt;RawEGI  |  sfv_eeg_011ts.raw, n_channels x n_times : 135 x 989490 (4947.4 sec), ~1019.5 MB, data loaded&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;creating-epochs&#34;&gt;Creating epochs&lt;/h2&gt;
&lt;p&gt;Now that we have done some primary artifact detections, we can create a first look on how our epochs look. Epochs are time-locked events of interest. Here, we look at the few hundred milliseconds before and after the onset of the last word of a sentence presentation. Before creating the epochs, we will run some custom codes to update the event arrays accordingly so the event labels are properly labeled ie. 1 for onsets, 2 for offsets.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# first find events related to tlst stim channel in the cleaned raw&lt;/span&gt;
events_tlst &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mne&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;find_events(raw, stim_channel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tlst&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# events_tlst is a array structure ie.  (1, 0, 1) and so far, the all the event tags are 1 which is not true&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# We will update the event tags with 1s and 2s with custom built function&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# update event ids in mne events array and double check sampling onset timing as sanity check&lt;/span&gt;
events_tlstS &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; extract_nslog_event&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;assign_event_id(df_tlst, events_tlst)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;updating mne event array and double checking sampling onset time...
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# epoching initially with metadata applied&lt;/span&gt;
event_id_tlst &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dict(lstS&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
tmin &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# start of each epoch&lt;/span&gt;
tmax &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# end of each epoch&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# set baseline to 0&lt;/span&gt;
baseline &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (tmin, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# picks specify which channels we are interested&lt;/span&gt;
picks &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mne&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pick_types(raw&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info, meg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;, eeg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, eog&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, stim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;, exclude&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bads&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# `metadata` field is used to put in our comprehensive pandas dataframe&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# it is useful for later creating evoked responses by conditions&lt;/span&gt;
epochs_tlstS &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mne&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Epochs(raw, events_tlstS, event_id_tlst, tmin, tmax, proj&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;, picks&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;picks,
                          baseline&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;baseline, preload&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, reject&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;, reject_by_annotation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, metadata&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;df_tlstS)
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;epochs_tlstS:&amp;#39;&lt;/span&gt;)
print(epochs_tlstS)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;epochs_tlstS:
&amp;lt;Epochs  |   388 events (all good), -0.25 - 0.8 sec, baseline [-0.25, 0], ~72.8 MB, data loaded, with metadata,
 &#39;lstS&#39;: 388&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We created epochs named &lt;code&gt;epochs_tlstS&lt;/code&gt; which is mne&amp;rsquo;s epochs instance. Note that the epochs are 388 instead of original 400. It is likely that the some epochs are dropped from annotations. Let&amp;rsquo;s see if it&amp;rsquo;s true.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# show drop percentage from mne.Epochs&lt;/span&gt;
drop_count &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(epochs_tlstS&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop_log)):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bad eye&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; epochs_tlstS&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop_log[j]:
        drop_count &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
print(str(drop_count) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; epochs dropped by eog annotation&amp;#39;&lt;/span&gt;)
print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;perecentage dropped: &amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(epochs_tlstS&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop_log_stats()))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;12 epochs dropped by eog annotation
perecentage dropped: 3.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;creating-evoked-response-erp&#34;&gt;Creating evoked response (ERP)&lt;/h2&gt;
&lt;p&gt;Everything looks good. We can create an evoked response by condition. Currently, the epochs_tlst contains all four conditions of the task. By creating an evoked response by condition, we can examine the data for each condition.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# create evoked respone using pandas query based on metadata created from previous epochs&lt;/span&gt;
evoked_tlst_c1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; epochs_tlstS[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;label==&amp;#39;lstS&amp;#39; and cond==&amp;#39;1&amp;#39;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;average()
evoked_tlst_c2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; epochs_tlstS[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;label==&amp;#39;lstS&amp;#39; and cond==&amp;#39;2&amp;#39;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;average()
evoked_tlst_c3 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; epochs_tlstS[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;label==&amp;#39;lstS&amp;#39; and cond==&amp;#39;3&amp;#39;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;average()
evoked_tlst_c4 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; epochs_tlstS[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;label==&amp;#39;lstS&amp;#39; and cond==&amp;#39;4&amp;#39;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;average()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Evoked responses are created by condition. Let&amp;rsquo;s just inspect the first one. The figure below will show the waveforms of all channels (except the ones marked bad and bipolar referenced channels) with total N epochs in that condition. Originally, N=100 for each condition.&lt;/p&gt;
&lt;p&gt;We can see something happening at 100ms to 300ms range after the onset of the word, which is time point 0s.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;print(evoked_tlst_c1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./walkthrough_basics_41_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Figure(460.8x216)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Figure above is in black and could be hard to inspect. A more interesting plot could be using &lt;code&gt;plot_joint&lt;/code&gt; method. You can see that most of the channels in the frontal region are showing flat, insignificant patterns. On the other hand, the right occipital (marked in red, purplish colors) is revealing potentially interesting results.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;print(evoked_tlst_c1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_joint(times&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;peaks&amp;#39;&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;/Users/Jin/Library/Python/2.7/lib/python/site-packages/mne/transforms.py:689: RuntimeWarning: invalid value encountered in divide
  out[:, 2] = np.arccos(cart[:, 2] / out[:, 0])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./walkthrough_basics_43_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Figure(576x302.4)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To avoid going through the same process everytime you load in a subject, we can save the progress by saving the resulted epochs (ie. &lt;code&gt;epochs_tlstS&lt;/code&gt; or raw instance). In the other notebook, we will continue with more advanced artifact detection using the saved epochs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;epochs_tlstS&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;save(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;epochs_tlsts-epo.fif&amp;#39;&lt;/span&gt;, split_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2GB&amp;#39;&lt;/span&gt;, fmt&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;single&amp;#39;&lt;/span&gt;, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;sources-and-useful-links&#34;&gt;Sources and useful links&lt;/h2&gt;
&lt;p&gt;MNE querying metadata: &lt;a href=&#34;https://martinos.org/mne/stable/auto_examples/preprocessing/plot_metadata_query.html&#34;&gt;https://martinos.org/mne/stable/auto_examples/preprocessing/plot_metadata_query.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;MNE annotations: &lt;a href=&#34;https://martinos.org/mne/stable/generated/mne.Annotations.html&#34;&gt;https://martinos.org/mne/stable/generated/mne.Annotations.html&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
